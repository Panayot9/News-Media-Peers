{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 00:34:25.721767: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "from notebooks.utils import _ALEXA_DATA_PATH, load_node_features, load_level_data, create_nodes, export_model_as_feature\n",
    "from train import run_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load audience overlap edges for level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-10 00:34:27 notebooks.utils INFO     Loaded 3489 nodes with records level <= 1 and child size:16981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('crooked.com', 'votesaveamerica.com'), ('crooked.com', 'art19.com'), ('crooked.com', 'promocodeportal.com'), ('crooked.com', 'mediamatters.org'), ('crooked.com', 'actblue.com')]\n"
     ]
    }
   ],
   "source": [
    "audience_overlap_sites = load_level_data(os.path.join(_ALEXA_DATA_PATH, 'corpus_2020_audience_overlap_sites_scrapping_result.json'), level=1)\n",
    "audience_overlap_sites_NODES = create_nodes(audience_overlap_sites)\n",
    "\n",
    "print(audience_overlap_sites_NODES[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>votesaveamerica.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>art19.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>promocodeportal.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>mediamatters.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>actblue.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source               target\n",
       "0  crooked.com  votesaveamerica.com\n",
       "1  crooked.com            art19.com\n",
       "2  crooked.com  promocodeportal.com\n",
       "3  crooked.com     mediamatters.org\n",
       "4  crooked.com          actblue.com"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df = pd.DataFrame(audience_overlap_sites_NODES, columns=['source', 'target'])\n",
    "\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all unique nodes in edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique nodes in edges: 10161 Sample: ['q13fox.com', 'influencewatch.org', 'dennisdemori.com', 'fiercehealthcare.com', 'jfranews.com.jo']\n"
     ]
    }
   ],
   "source": [
    "nodes_in_edges = list(set(edge_df.source.unique().tolist() + edge_df.target.unique().tolist()))\n",
    "print('Number of unique nodes in edges:', len(nodes_in_edges), 'Sample:', nodes_in_edges[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load all node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alexa_rank</th>\n",
       "      <th>daily_pageviews_per_visitor</th>\n",
       "      <th>daily_time_on_site</th>\n",
       "      <th>total_sites_linking_in</th>\n",
       "      <th>bounce_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whistleblowersandrelators.com</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geokov.com</th>\n",
       "      <td>2238341.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trainingandfacilitation.ca</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plumsolutions.com.au</th>\n",
       "      <td>1023533.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbdailyupdate.com</th>\n",
       "      <td>145283.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>179.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               alexa_rank  daily_pageviews_per_visitor  \\\n",
       "site                                                                     \n",
       "whistleblowersandrelators.com         NaN                          NaN   \n",
       "geokov.com                      2238341.0                          1.0   \n",
       "trainingandfacilitation.ca            NaN                          NaN   \n",
       "plumsolutions.com.au            1023533.0                          1.0   \n",
       "dbdailyupdate.com                145283.0                          1.7   \n",
       "\n",
       "                               daily_time_on_site  total_sites_linking_in  \\\n",
       "site                                                                        \n",
       "whistleblowersandrelators.com                 NaN                     NaN   \n",
       "geokov.com                                    NaN                    60.0   \n",
       "trainingandfacilitation.ca                    NaN                     NaN   \n",
       "plumsolutions.com.au                        138.0                    60.0   \n",
       "dbdailyupdate.com                           179.0                    64.0   \n",
       "\n",
       "                               bounce_rate  \n",
       "site                                        \n",
       "whistleblowersandrelators.com          NaN  \n",
       "geokov.com                           0.900  \n",
       "trainingandfacilitation.ca             NaN  \n",
       "plumsolutions.com.au                 0.813  \n",
       "dbdailyupdate.com                    0.756  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_df = load_node_features()\n",
    "node_features_df = node_features_df.set_index('site')\n",
    "node_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_df = node_features_df.loc[nodes_in_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10161 entries, q13fox.com to carefree.org\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   alexa_rank                   7465 non-null   float64\n",
      " 1   daily_pageviews_per_visitor  7466 non-null   float64\n",
      " 2   daily_time_on_site           5566 non-null   float64\n",
      " 3   total_sites_linking_in       9861 non-null   float64\n",
      " 4   bounce_rate                  5179 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 476.3+ KB\n"
     ]
    }
   ],
   "source": [
    "node_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fill all missing alexa_rank and total_sites_linking_in with 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10161 entries, q13fox.com to carefree.org\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   alexa_rank                   10161 non-null  float64\n",
      " 1   daily_pageviews_per_visitor  7466 non-null   float64\n",
      " 2   daily_time_on_site           5566 non-null   float64\n",
      " 3   total_sites_linking_in       10161 non-null  float64\n",
      " 4   bounce_rate                  5179 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 476.3+ KB\n"
     ]
    }
   ],
   "source": [
    "node_features_df.alexa_rank = node_features_df.alexa_rank.fillna(0)\n",
    "node_features_df.total_sites_linking_in = node_features_df.total_sites_linking_in.fillna(0)\n",
    "node_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normalizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "node_features_df['normalized_alexa_rank'] = node_features_df['alexa_rank'].apply(lambda x: 1/x if x else 0)\n",
    "node_features_df['normalized_total_sites_linked_in'] = node_features_df['total_sites_linking_in'].apply(lambda x: math.log2(x) if x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 10161, Edges: 17010\n",
      "\n",
      " Node types:\n",
      "  default: [10161]\n",
      "    Features: float32 vector, length 2\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [17010]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "import stellargraph as sg\n",
    "\n",
    "G = sg.StellarGraph(nodes=node_features_df.loc[nodes_in_edges, ['normalized_alexa_rank', 'normalized_total_sites_linked_in']], edges=edge_df)\n",
    "\n",
    "print(G.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised GraphSAGE\n",
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "from stellargraph.layer import GraphSAGE, link_classification\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'ip' method to combine node embeddings into edge embeddings\n"
     ]
    }
   ],
   "source": [
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "from stellargraph.layer import GraphSAGE, link_classification\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# 1. Specify the other optional parameter values: root nodes, the number of walks to take per node, the length of each walk, and random seed.\n",
    "\n",
    "nodes = list(G.nodes())\n",
    "number_of_walks = 1\n",
    "length = 5\n",
    "\n",
    "# 2. Create the UnsupervisedSampler instance with the relevant parameters passed to it.\n",
    "unsupervised_samples = UnsupervisedSampler(G, nodes=nodes, length=length, number_of_walks=number_of_walks)\n",
    "\n",
    "# 3. Create a node pair generator:\n",
    "batch_size = 128\n",
    "epochs = 4\n",
    "num_samples = [10, 5]\n",
    "\n",
    "graphsage_link_generator = GraphSAGELinkGenerator(G, batch_size, num_samples)\n",
    "train_graphsage_link_gen = graphsage_link_generator.flow(unsupervised_samples)\n",
    "\n",
    "layer_sizes = [128, 512]\n",
    "graphsage = GraphSAGE(\n",
    "    layer_sizes=layer_sizes, generator=graphsage_link_generator, bias=True, dropout=0.0, normalize=\"l2\"\n",
    ")\n",
    "\n",
    "# Build the model and expose input and output sockets of graphsage, for node pair inputs:\n",
    "x_inp, x_out = graphsage.in_out_tensors()\n",
    "\n",
    "prediction = link_classification(\n",
    "    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    ")(x_out)\n",
    "\n",
    "graphsage_model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "\n",
    "graphsage_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    metrics=['acc'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "636/636 [==============================] - 81s 127ms/step - loss: 5.9605e-08 - acc: 0.49961s - loss: 5.9636e-08 \n",
      "Epoch 2/4\n",
      "636/636 [==============================] - 90s 140ms/step - loss: 5.9605e-08 - acc: 0.4995 ETA: 4s -\n",
      "Epoch 3/4\n",
      "636/636 [==============================] - 73s 114ms/step - loss: 5.9605e-08 - acc: 0.4995\n",
      "Epoch 4/4\n",
      "636/636 [==============================] - 79s 124ms/step - loss: 5.9605e-08 - acc: 0.49978s - loss: 5.9809e-08 - ETA - ETA: 2s - loss: 5.9697e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch 1/4\\n   2/5047 [..............................] - ETA: 3:09 - loss: 0.7847 - binary_accuracy: 0.515 - ETA: 9:20 - loss: 0.7903 - binary_accuracy: 0.5039WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.2059s). Check your callbacks.\\n5047/5047 [==============================] - 548s 109ms/step - loss: 0.5881 - binary_accuracy: 0.7075 8:59 - ETA: 8:3 - ETA: 8:01 - - ETA: 7:50 - loss: 0.6312  - ETA: 7:35 - loss: 0.6251 - bin - ETA: 7:13 - loss: 0.6196 - binary_acc - ETA: 7:11 - loss: 0.6192 -  - ETA: 7:08 - loss: 0.6188 -  - ETA: 7:04 - loss: 0.6183 - binary_accu - ETA: 7:04 - loss: 0.6179 - binary_a - ETA: 7:01 - loss: 0.6174 -  - ETA: 6:52 - los - ETA: 6:48 - loss: 0.6148 - binary_accuracy: 0. - ETA: 6:47 - loss: 0.6146 - - ETA: 6:45 - loss: 0.6 - ETA: 6:41  - ETA: 6:31 - loss: 0.6121 - binary_accuracy: 0.6 - ETA: 6:30 - loss: 0. - ETA: 6:26 - los - ETA: 6:02 - loss: 0.608 - ETA: 5:58 -  - ETA: 5:54  - ETA: 4:32 - loss: 0.6004 -  - ETA: 4:30 - loss: 0.6001 - binary_accuracy:  - ETA: 4:29 - loss: 0.6001 - binary_accuracy: - ETA: 4:28 - loss: 0.6001 - binary_accu - ETA: 10s - loss: 0.5883 - bina - ETA: 9s - loss: 0.5883 - binary_accuracy: 0.7 - ETA: 9s - loss: 0.5883 - binary \\nEpoch 2/4\\n5047/5047 [==============================] - 547s 108ms/step - loss: 0.5730 - binary_accuracy: 0.7293 9:22 - loss: 0.5795 - binary_accur - ETA: 8:40 - loss: 0.5779 - binary_accuracy - ETA: 8:38 - loss: 0.5780 - binary_accuracy: 0. - ETA: 8:37 - loss: 0.5778 - binary_accuracy - ETA: 8:36 - loss: 0.5779 - b - ETA:  - ETA: 5:54 - loss: 0.57 - ETA: 5:31 - lo - ETA: 5:02 - loss: 0.57 - ETA: 4:58 - loss: 0.5736 - binary_accuracy: 0.7 - ETA: 4:58 - loss: 0.5737 - - ETA: 4:48 - loss: 0.5738 - binary_accurac - ETA: 4:48 - l - ETA:  - ETA: 4:32 - loss: - ETA: 4:28 - loss: 0.5738 - binary_accuracy: 0.7 - ETA: 4:28 - loss: 0.5738  -  - ETA: 3:46 - loss: 0.5737 - binary_accuracy: 0.726 - ET - ETA: 3:41 - loss: 0.5737 - binary_ac - ETA: 3:39 -  - ETA: 3:34 - loss: 0.5737 - binary_ac - E - ETA: 2:50 - loss: 0.5736 - binary_accuracy: 0. - ETA: 2:24 - loss: 0.5735 - binary_accuracy: 0. - ETA: 2:23 - -\\nEpoch 3/4\\n5047/5047 [==============================] - 550s 109ms/step - loss: 0.5698 - binary_accuracy: 0.7398\\nEpoch 4/4\\n5047/5047 [==============================] - 546s 108ms/step - loss: 0.5698 - binary_accuracy: 0.7398 10:00 - loss:  - ETA: 4:31 - lo - ETA: 4:27 - loss: 0.5700 - binary_accu - - ETA: 4:07 - loss: 0.5699 - binary_accura - ETA: 3:59 - ETA: 3:55 - loss - ETA:  - ETA: 3:39 - loss: 0.5701 - binary_accuracy - ETA: 3:38 - loss: 0.5701 - binary_ac - ETA: 3: - ETA: 3:31 - loss: 0.5701 - binary_acc - ETA: 3:30 - loss: 0.5702 - bin - ETA: 3:27 - loss: 0 - ETA:  - ETA: 2:53 - lo - E - ETA: 2:37 - l - ETA: 2:32 - loss:  - ETA: 2:28 - loss: 0.5703 - binary_accuracy: 0. - ETA: 2:28 - loss: 0.5703 - binary_accura - ETA: 2:27 - loss: 0.57 - ETA: 2:23 - loss: 0.5702 - b - ETA: 2:21 -  - E - ETA: 54s - loss: 0.5698 - binary_a - ETA: 4s - loss: 0.5\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = graphsage_model.fit(\n",
    "    train_graphsage_link_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=False,\n",
    "    workers=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Epoch 1/4\n",
    "   2/5047 [..............................] - ETA: 3:09 - loss: 0.7847 - binary_accuracy: 0.515 - ETA: 9:20 - loss: 0.7903 - binary_accuracy: 0.5039WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.2059s). Check your callbacks.\n",
    "5047/5047 [==============================] - 548s 109ms/step - loss: 0.5881 - binary_accuracy: 0.7075 8:59 - ETA: 8:3 - ETA: 8:01 - - ETA: 7:50 - loss: 0.6312  - ETA: 7:35 - loss: 0.6251 - bin - ETA: 7:13 - loss: 0.6196 - binary_acc - ETA: 7:11 - loss: 0.6192 -  - ETA: 7:08 - loss: 0.6188 -  - ETA: 7:04 - loss: 0.6183 - binary_accu - ETA: 7:04 - loss: 0.6179 - binary_a - ETA: 7:01 - loss: 0.6174 -  - ETA: 6:52 - los - ETA: 6:48 - loss: 0.6148 - binary_accuracy: 0. - ETA: 6:47 - loss: 0.6146 - - ETA: 6:45 - loss: 0.6 - ETA: 6:41  - ETA: 6:31 - loss: 0.6121 - binary_accuracy: 0.6 - ETA: 6:30 - loss: 0. - ETA: 6:26 - los - ETA: 6:02 - loss: 0.608 - ETA: 5:58 -  - ETA: 5:54  - ETA: 4:32 - loss: 0.6004 -  - ETA: 4:30 - loss: 0.6001 - binary_accuracy:  - ETA: 4:29 - loss: 0.6001 - binary_accuracy: - ETA: 4:28 - loss: 0.6001 - binary_accu - ETA: 10s - loss: 0.5883 - bina - ETA: 9s - loss: 0.5883 - binary_accuracy: 0.7 - ETA: 9s - loss: 0.5883 - binary \n",
    "Epoch 2/4\n",
    "5047/5047 [==============================] - 547s 108ms/step - loss: 0.5730 - binary_accuracy: 0.7293 9:22 - loss: 0.5795 - binary_accur - ETA: 8:40 - loss: 0.5779 - binary_accuracy - ETA: 8:38 - loss: 0.5780 - binary_accuracy: 0. - ETA: 8:37 - loss: 0.5778 - binary_accuracy - ETA: 8:36 - loss: 0.5779 - b - ETA:  - ETA: 5:54 - loss: 0.57 - ETA: 5:31 - lo - ETA: 5:02 - loss: 0.57 - ETA: 4:58 - loss: 0.5736 - binary_accuracy: 0.7 - ETA: 4:58 - loss: 0.5737 - - ETA: 4:48 - loss: 0.5738 - binary_accurac - ETA: 4:48 - l - ETA:  - ETA: 4:32 - loss: - ETA: 4:28 - loss: 0.5738 - binary_accuracy: 0.7 - ETA: 4:28 - loss: 0.5738  -  - ETA: 3:46 - loss: 0.5737 - binary_accuracy: 0.726 - ET - ETA: 3:41 - loss: 0.5737 - binary_ac - ETA: 3:39 -  - ETA: 3:34 - loss: 0.5737 - binary_ac - E - ETA: 2:50 - loss: 0.5736 - binary_accuracy: 0. - ETA: 2:24 - loss: 0.5735 - binary_accuracy: 0. - ETA: 2:23 - -\n",
    "Epoch 3/4\n",
    "5047/5047 [==============================] - 550s 109ms/step - loss: 0.5698 - binary_accuracy: 0.7398\n",
    "Epoch 4/4\n",
    "5047/5047 [==============================] - 546s 108ms/step - loss: 0.5698 - binary_accuracy: 0.7398 10:00 - loss:  - ETA: 4:31 - lo - ETA: 4:27 - loss: 0.5700 - binary_accu - - ETA: 4:07 - loss: 0.5699 - binary_accura - ETA: 3:59 - ETA: 3:55 - loss - ETA:  - ETA: 3:39 - loss: 0.5701 - binary_accuracy - ETA: 3:38 - loss: 0.5701 - binary_ac - ETA: 3: - ETA: 3:31 - loss: 0.5701 - binary_acc - ETA: 3:30 - loss: 0.5702 - bin - ETA: 3:27 - loss: 0 - ETA:  - ETA: 2:53 - lo - E - ETA: 2:37 - l - ETA: 2:32 - loss:  - ETA: 2:28 - loss: 0.5703 - binary_accuracy: 0. - ETA: 2:28 - loss: 0.5703 - binary_accura - ETA: 2:27 - loss: 0.57 - ETA: 2:23 - loss: 0.5702 - b - ETA: 2:21 -  - E - ETA: 54s - loss: 0.5698 - binary_a - ETA: 4s - loss: 0.5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 5s 57ms/step\n",
      "Sample: [-0.015975967049598694, -0.004238066729158163, -0.029331792145967484, -0.04764040559530258, -0.028530171141028404, 0.030409863218665123, -0.03388119488954544, -0.017634505406022072, 0.0049674599431455135, 0.05562857538461685]\n"
     ]
    }
   ],
   "source": [
    "embedding_model = keras.Model(inputs=x_inp[0::2], outputs=x_out[0])\n",
    "\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator\n",
    "\n",
    "node_gen = GraphSAGENodeGenerator(G, batch_size, num_samples).flow(node_features_df.index)\n",
    "node_embeddings = embedding_model.predict(node_gen, workers=4, verbose=1)\n",
    "\n",
    "embeddings_wv = dict(zip(node_features_df.index.tolist(), node_embeddings.tolist()))\n",
    "\n",
    "print('Sample:', embeddings_wv['crooked.com'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export embeddings as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/panayot/Documents/News-Media-Peers/data/acl2020/features/graph_sage_audience_overlap_level_1.json'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_model_as_feature(embeddings_wv, 'graph_sage_audience_overlap_level_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+---------------+--------------------+-------------------------------------+\n",
      "| task | classification_mode | type_training | normalize_features |               features              |\n",
      "+------+---------------------+---------------+--------------------+-------------------------------------+\n",
      "| fact |  single classifier  |    combine    |       False        | graph_sage_audience_overlap_level_1 |\n",
      "+------+---------------------+---------------+--------------------+-------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-10 00:43:35 train        INFO     Start training...\n",
      "01-10 00:43:35 train        INFO     Fold: 0\n",
      "01-10 00:43:44 train        INFO     Fold: 1\n",
      "01-10 00:43:51 train        INFO     Fold: 2\n",
      "01-10 00:43:58 train        INFO     Fold: 3\n",
      "01-10 00:44:04 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+---------------+--------------------+-------------------------------------+-------------------+------------------+--------------------+--------------------+\n",
      "| task | classification_mode | type_training | normalize_features |               features              |      Macro-F1     |     Accuracy     |  Flip error-rate   |        MAE         |\n",
      "+------+---------------------+---------------+--------------------+-------------------------------------+-------------------+------------------+--------------------+--------------------+\n",
      "| fact |  single classifier  |    combine    |       False        | graph_sage_audience_overlap_level_1 | 28.22290703646636 | 52.9685681024447 | 16.530849825378347 | 0.6356228172293364 |\n",
      "+------+---------------------+---------------+--------------------+-------------------------------------+-------------------+------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "run_experiment(features=\"graph_sage_audience_overlap_level_1\", normalize_features=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "940b4c110c3cebababd37dc6cec19477a44e469d32c41a0eaa8eeb689ff0386b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('site_similarity': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "72b3faef5542ae75c34eb0d3b11ce0fc432eb00b9ccfc309dfbebb58f482608a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
