{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 23:04:22.073400: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "from notebooks.utils import (\n",
    "    get_referral_sites_edges, export_model_as_feature, create_node2vec_model\n",
    ")\n",
    "from train import run_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load audience overlap edges for level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:04:22 notebooks.utils INFO     Processing level 0\n",
      "02-26 23:04:22 notebooks.utils INFO     Node length: 3922\n",
      "02-26 23:04:22 notebooks.utils INFO     Distinct node length: 3922\n",
      "02-26 23:04:22 notebooks.utils INFO     Processing level 1\n",
      "02-26 23:04:22 notebooks.utils INFO     Node length: 11144\n",
      "02-26 23:04:22 notebooks.utils INFO     Distinct node length: 11144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('news.abs-cbn.com', 'rappler.com'), ('gopusa.com', 'thepoliticalinsider.com'), ('newser.com', 'idealmedia.com'), ('thediplomat.com', 'nationalinterest.org'), ('bannedinformation.com', 'edmallday.com')]\n"
     ]
    }
   ],
   "source": [
    "level = 1\n",
    "referral_sites_NODES = get_referral_sites_edges(data_year=2018, level=level)\n",
    "\n",
    "print(referral_sites_NODES[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news.abs-cbn.com</td>\n",
       "      <td>rappler.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gopusa.com</td>\n",
       "      <td>thepoliticalinsider.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newser.com</td>\n",
       "      <td>idealmedia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thediplomat.com</td>\n",
       "      <td>nationalinterest.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bannedinformation.com</td>\n",
       "      <td>edmallday.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  source                   target\n",
       "0       news.abs-cbn.com              rappler.com\n",
       "1             gopusa.com  thepoliticalinsider.com\n",
       "2             newser.com           idealmedia.com\n",
       "3        thediplomat.com     nationalinterest.org\n",
       "4  bannedinformation.com            edmallday.com"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df = pd.DataFrame(referral_sites_NODES, columns=['source', 'target'])\n",
    "\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 8250, Edges: 15066\n",
      "\n",
      " Node types:\n",
      "  default: [8250]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [15066]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "import stellargraph as sg\n",
    "\n",
    "G = sg.StellarGraph(edges=edge_df)\n",
    "\n",
    "print(G.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Node2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creating random walks\n",
      "Number of random walks: 82500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:13:57 gensim.models.word2vec INFO     collecting all words and their counts\n",
      "02-26 23:13:57 gensim.models.word2vec INFO     PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     PROGRESS: at sentence #10000, processed 1000000 words, keeping 8134 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 corpus_2018_referral_sites_lvl_one_unweighted_64D.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:13:58 gensim.models.word2vec INFO     PROGRESS: at sentence #20000, processed 2000000 words, keeping 8250 word types\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     PROGRESS: at sentence #30000, processed 3000000 words, keeping 8250 word types\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     PROGRESS: at sentence #40000, processed 4000000 words, keeping 8250 word types\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     PROGRESS: at sentence #50000, processed 5000000 words, keeping 8250 word types\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     PROGRESS: at sentence #60000, processed 6000000 words, keeping 8250 word types\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     PROGRESS: at sentence #70000, processed 7000000 words, keeping 8250 word types\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     PROGRESS: at sentence #80000, processed 8000000 words, keeping 8250 word types\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     collected 8250 word types from a corpus of 8250000 raw words and 82500 sentences\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     Creating a fresh vocabulary\n",
      "02-26 23:13:58 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 8250 unique words (100.0%% of original 8250, drops 0)', 'datetime': '2022-02-26T23:13:58.937272', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:13:58 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 8250000 word corpus (100.0%% of original 8250000, drops 0)', 'datetime': '2022-02-26T23:13:58.938103', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:13:58 gensim.models.word2vec INFO     deleting the raw counts dictionary of 8250 items\n",
      "02-26 23:13:59 gensim.models.word2vec INFO     sample=0.001 downsamples 0 most-common words\n",
      "02-26 23:13:59 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8250000 word corpus (100.0%% of prior 8250000)', 'datetime': '2022-02-26T23:13:59.001084', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:13:59 gensim.models.word2vec INFO     estimated required memory for 8250 words and 64 dimensions: 8349000 bytes\n",
      "02-26 23:13:59 gensim.models.word2vec INFO     resetting layer weights\n",
      "02-26 23:13:59 gensim.utils INFO     Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-02-26T23:13:59.102408', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "02-26 23:13:59 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training model with 2 workers on 8250 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-02-26T23:13:59.103129', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:14:00 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 3.52% examples, 277274 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:01 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 7.88% examples, 316119 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:02 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 12.73% examples, 340541 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:03 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 18.06% examples, 362439 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:04 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 24.48% examples, 394886 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:05 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 31.03% examples, 418003 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:06 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 37.82% examples, 437306 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:07 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 44.73% examples, 452431 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:14:08 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 52.00% examples, 467343 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:09 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 57.58% examples, 464783 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:10 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 62.30% examples, 457733 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:11 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 67.76% examples, 456859 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:12 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 73.33% examples, 456454 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:13 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 79.15% examples, 457441 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:14 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 84.85% examples, 458147 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:15 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 92.00% examples, 466154 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:16 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 99.39% examples, 474326 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:16 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:14:16 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:14:16 gensim.models.word2vec INFO     EPOCH - 1 : training on 8250000 raw words (8250000 effective words) took 17.4s, 474934 effective words/s\n",
      "02-26 23:14:17 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 6.91% examples, 559292 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:18 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 14.42% examples, 586613 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:19 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 21.94% examples, 594617 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:20 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 29.21% examples, 595549 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:21 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 36.73% examples, 597473 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:14:22 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 44.24% examples, 599631 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:23 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 51.76% examples, 600811 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:14:24 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 59.27% examples, 602111 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:25 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 66.55% examples, 601055 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:26 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 73.70% examples, 599734 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:27 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 81.21% examples, 601059 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:28 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 88.73% examples, 601610 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:29 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 95.88% examples, 600465 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:30 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:14:30 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:14:30 gensim.models.word2vec INFO     EPOCH - 2 : training on 8250000 raw words (8250000 effective words) took 13.7s, 600852 effective words/s\n",
      "02-26 23:14:31 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 7.39% examples, 600175 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:32 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 14.42% examples, 587437 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:33 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 21.94% examples, 594973 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:34 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 29.45% examples, 599579 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:35 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 36.73% examples, 599257 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:36 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 44.24% examples, 601261 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:37 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 51.76% examples, 602761 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:38 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 59.15% examples, 603540 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:39 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 66.55% examples, 603510 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:40 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 74.06% examples, 604425 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:41 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 81.58% examples, 604965 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:42 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 89.09% examples, 605164 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:14:43 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 96.61% examples, 605120 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:43 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:14:43 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:14:43 gensim.models.word2vec INFO     EPOCH - 3 : training on 8250000 raw words (8250000 effective words) took 13.6s, 605129 effective words/s\n",
      "02-26 23:14:44 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 7.27% examples, 598488 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:45 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 14.79% examples, 608805 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:46 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 21.70% examples, 593494 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:47 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 29.45% examples, 601392 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:48 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 36.97% examples, 602163 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:14:49 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 44.24% examples, 601674 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:50 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 51.64% examples, 601749 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:51 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 59.15% examples, 603834 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:52 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 66.67% examples, 604744 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:53 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 73.94% examples, 604257 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:54 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 81.45% examples, 604683 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:55 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 88.85% examples, 604653 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:56 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 96.36% examples, 604888 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:57 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:14:57 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:14:57 gensim.models.word2vec INFO     EPOCH - 4 : training on 8250000 raw words (8250000 effective words) took 13.6s, 604637 effective words/s\n",
      "02-26 23:14:58 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 7.39% examples, 598921 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:14:59 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 14.42% examples, 584866 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:00 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 21.94% examples, 590437 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:01 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 29.45% examples, 595195 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:02 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 36.97% examples, 597514 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:03 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 44.48% examples, 599083 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:04 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 52.00% examples, 599571 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:05 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 59.52% examples, 601243 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:06 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 67.03% examples, 602203 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:07 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 74.55% examples, 602963 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:08 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 82.06% examples, 604088 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:09 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 89.58% examples, 604896 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:10 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 96.73% examples, 603551 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     EPOCH - 5 : training on 8250000 raw words (8250000 effective words) took 13.7s, 602119 effective words/s\n",
      "02-26 23:15:11 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training on 41250000 raw words (41250000 effective words) took 72.1s, 572139 effective words/s', 'datetime': '2022-02-26T23:15:11.202132', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:15:11 gensim.utils INFO     Word2Vec lifecycle event {'params': 'Word2Vec(vocab=8250, vector_size=64, alpha=0.025)', 'datetime': '2022-02-26T23:15:11.202621', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "02-26 23:15:11 gensim.utils INFO     Word2Vec lifecycle event {'fname_or_handle': '/Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_64D.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-02-26T23:15:11.203962', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "02-26 23:15:11 gensim.utils INFO     not storing attribute cum_table\n",
      "02-26 23:15:11 gensim.utils INFO     saved /Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_64D.model\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     collecting all words and their counts\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     PROGRESS: at sentence #10000, processed 1000000 words, keeping 8134 word types\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     PROGRESS: at sentence #20000, processed 2000000 words, keeping 8250 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful save of model: corpus_2018_referral_sites_lvl_one_unweighted_64D.model!\n",
      "128 corpus_2018_referral_sites_lvl_one_unweighted_128D.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:15:11 gensim.models.word2vec INFO     PROGRESS: at sentence #30000, processed 3000000 words, keeping 8250 word types\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     PROGRESS: at sentence #40000, processed 4000000 words, keeping 8250 word types\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     PROGRESS: at sentence #50000, processed 5000000 words, keeping 8250 word types\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     PROGRESS: at sentence #60000, processed 6000000 words, keeping 8250 word types\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     PROGRESS: at sentence #70000, processed 7000000 words, keeping 8250 word types\n",
      "02-26 23:15:11 gensim.models.word2vec INFO     PROGRESS: at sentence #80000, processed 8000000 words, keeping 8250 word types\n",
      "02-26 23:15:12 gensim.models.word2vec INFO     collected 8250 word types from a corpus of 8250000 raw words and 82500 sentences\n",
      "02-26 23:15:12 gensim.models.word2vec INFO     Creating a fresh vocabulary\n",
      "02-26 23:15:12 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 8250 unique words (100.0%% of original 8250, drops 0)', 'datetime': '2022-02-26T23:15:12.042704', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:15:12 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 8250000 word corpus (100.0%% of original 8250000, drops 0)', 'datetime': '2022-02-26T23:15:12.043338', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:15:12 gensim.models.word2vec INFO     deleting the raw counts dictionary of 8250 items\n",
      "02-26 23:15:12 gensim.models.word2vec INFO     sample=0.001 downsamples 0 most-common words\n",
      "02-26 23:15:12 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8250000 word corpus (100.0%% of prior 8250000)', 'datetime': '2022-02-26T23:15:12.095665', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:15:12 gensim.models.word2vec INFO     estimated required memory for 8250 words and 128 dimensions: 12573000 bytes\n",
      "02-26 23:15:12 gensim.models.word2vec INFO     resetting layer weights\n",
      "02-26 23:15:12 gensim.utils INFO     Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-02-26T23:15:12.180169', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "02-26 23:15:12 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training model with 2 workers on 8250 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-02-26T23:15:12.180837', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:15:13 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 4.24% examples, 344496 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:14 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 9.09% examples, 371185 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:15 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 14.42% examples, 392023 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:16 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 20.00% examples, 406993 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:17 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 25.58% examples, 416742 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:18 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 31.27% examples, 424725 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:19 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 37.33% examples, 434992 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:20 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 43.27% examples, 441796 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:21 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 49.45% examples, 449064 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:22 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 55.64% examples, 453990 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:23 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 61.94% examples, 459206 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:24 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 68.12% examples, 463013 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:25 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 74.42% examples, 467023 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:26 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 80.85% examples, 471033 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:27 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 87.15% examples, 474245 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:28 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 93.70% examples, 477920 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:29 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:15:29 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:15:29 gensim.models.word2vec INFO     EPOCH - 1 : training on 8250000 raw words (8250000 effective words) took 17.1s, 481225 effective words/s\n",
      "02-26 23:15:30 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 6.18% examples, 498139 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:31 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 13.09% examples, 532725 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:32 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 19.52% examples, 530944 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:33 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 26.30% examples, 536640 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:34 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 32.85% examples, 536169 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:35 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 39.03% examples, 531242 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:36 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 45.45% examples, 530705 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:37 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 52.24% examples, 534034 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:38 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 58.79% examples, 534036 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:39 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 65.70% examples, 536250 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:40 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 72.24% examples, 536156 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:41 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 79.03% examples, 536966 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:42 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 85.58% examples, 536767 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:43 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 92.12% examples, 535801 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:44 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 98.67% examples, 535343 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:44 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:15:44 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:15:44 gensim.models.word2vec INFO     EPOCH - 2 : training on 8250000 raw words (8250000 effective words) took 15.4s, 535892 effective words/s\n",
      "02-26 23:15:45 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 6.67% examples, 535547 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:46 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 13.21% examples, 534493 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:47 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 20.00% examples, 541469 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:48 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 26.55% examples, 539853 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:49 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 33.33% examples, 542133 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:50 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 39.88% examples, 541180 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:51 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 46.67% examples, 542622 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:52 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 53.21% examples, 541938 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:53 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 60.12% examples, 544631 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:54 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 66.79% examples, 544344 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:55 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 73.33% examples, 543799 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:56 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 80.12% examples, 544206 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:57 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 87.03% examples, 545891 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:58 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 93.70% examples, 545706 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:15:59 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:15:59 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:15:59 gensim.models.word2vec INFO     EPOCH - 3 : training on 8250000 raw words (8250000 effective words) took 15.1s, 545478 effective words/s\n",
      "02-26 23:16:00 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 6.42% examples, 510069 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:01 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 12.97% examples, 524098 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:02 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 19.76% examples, 533522 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:03 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 26.42% examples, 536347 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:16:04 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 33.09% examples, 537021 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:05 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 39.88% examples, 539049 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:06 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 46.42% examples, 538398 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:07 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 52.97% examples, 537092 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:09 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 59.64% examples, 538113 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:10 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 66.30% examples, 539266 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:11 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 72.61% examples, 536651 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:12 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 79.39% examples, 538326 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:13 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 86.06% examples, 539027 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:14 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 92.85% examples, 539801 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:15 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 99.52% examples, 540468 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:15 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:16:15 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:16:15 gensim.models.word2vec INFO     EPOCH - 4 : training on 8250000 raw words (8250000 effective words) took 15.3s, 540236 effective words/s\n",
      "02-26 23:16:16 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 6.67% examples, 535973 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:17 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 13.45% examples, 545407 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:18 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 20.24% examples, 548205 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:19 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 27.03% examples, 548236 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:20 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 33.82% examples, 549130 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:21 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 40.36% examples, 547195 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:22 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 46.67% examples, 541582 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:23 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 53.33% examples, 542432 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:24 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 60.12% examples, 543695 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:25 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 66.79% examples, 543243 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:26 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 73.58% examples, 544007 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:27 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 80.36% examples, 544439 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:28 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 87.15% examples, 545152 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:29 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 93.94% examples, 545253 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     EPOCH - 5 : training on 8250000 raw words (8250000 effective words) took 15.2s, 543698 effective words/s\n",
      "02-26 23:16:30 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training on 41250000 raw words (41250000 effective words) took 78.1s, 527994 effective words/s', 'datetime': '2022-02-26T23:16:30.307776', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:16:30 gensim.utils INFO     Word2Vec lifecycle event {'params': 'Word2Vec(vocab=8250, vector_size=128, alpha=0.025)', 'datetime': '2022-02-26T23:16:30.308501', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "02-26 23:16:30 gensim.utils INFO     Word2Vec lifecycle event {'fname_or_handle': '/Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_128D.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-02-26T23:16:30.309728', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "02-26 23:16:30 gensim.utils INFO     not storing attribute cum_table\n",
      "02-26 23:16:30 gensim.utils INFO     saved /Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_128D.model\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     collecting all words and their counts\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     PROGRESS: at sentence #10000, processed 1000000 words, keeping 8134 word types\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     PROGRESS: at sentence #20000, processed 2000000 words, keeping 8250 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful save of model: corpus_2018_referral_sites_lvl_one_unweighted_128D.model!\n",
      "256 corpus_2018_referral_sites_lvl_one_unweighted_256D.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:16:30 gensim.models.word2vec INFO     PROGRESS: at sentence #30000, processed 3000000 words, keeping 8250 word types\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     PROGRESS: at sentence #40000, processed 4000000 words, keeping 8250 word types\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     PROGRESS: at sentence #50000, processed 5000000 words, keeping 8250 word types\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     PROGRESS: at sentence #60000, processed 6000000 words, keeping 8250 word types\n",
      "02-26 23:16:30 gensim.models.word2vec INFO     PROGRESS: at sentence #70000, processed 7000000 words, keeping 8250 word types\n",
      "02-26 23:16:31 gensim.models.word2vec INFO     PROGRESS: at sentence #80000, processed 8000000 words, keeping 8250 word types\n",
      "02-26 23:16:31 gensim.models.word2vec INFO     collected 8250 word types from a corpus of 8250000 raw words and 82500 sentences\n",
      "02-26 23:16:31 gensim.models.word2vec INFO     Creating a fresh vocabulary\n",
      "02-26 23:16:31 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 8250 unique words (100.0%% of original 8250, drops 0)', 'datetime': '2022-02-26T23:16:31.143432', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:16:31 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 8250000 word corpus (100.0%% of original 8250000, drops 0)', 'datetime': '2022-02-26T23:16:31.144138', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:16:31 gensim.models.word2vec INFO     deleting the raw counts dictionary of 8250 items\n",
      "02-26 23:16:31 gensim.models.word2vec INFO     sample=0.001 downsamples 0 most-common words\n",
      "02-26 23:16:31 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8250000 word corpus (100.0%% of prior 8250000)', 'datetime': '2022-02-26T23:16:31.196003', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:16:31 gensim.models.word2vec INFO     estimated required memory for 8250 words and 256 dimensions: 21021000 bytes\n",
      "02-26 23:16:31 gensim.models.word2vec INFO     resetting layer weights\n",
      "02-26 23:16:31 gensim.utils INFO     Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-02-26T23:16:31.295011', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "02-26 23:16:31 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training model with 2 workers on 8250 vocabulary and 256 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-02-26T23:16:31.295710', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:16:32 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 2.79% examples, 220300 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:33 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 5.94% examples, 233010 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:34 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 9.09% examples, 240633 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:35 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 12.48% examples, 248145 words/s, in_qsize 2, out_qsize 1\n",
      "02-26 23:16:36 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 15.15% examples, 241610 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:37 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 18.30% examples, 242858 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:38 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 20.85% examples, 236851 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:39 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 23.27% examples, 232307 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:16:40 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 25.82% examples, 229490 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:41 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 29.09% examples, 233347 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:42 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 32.36% examples, 235458 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:43 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 36.00% examples, 240155 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:44 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 39.76% examples, 245334 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:45 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 43.52% examples, 248985 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:46 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 47.39% examples, 252980 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:47 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 51.27% examples, 256935 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:48 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 55.15% examples, 260253 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:49 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 59.03% examples, 263412 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:50 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 62.91% examples, 265945 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:51 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 66.91% examples, 269012 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:52 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 70.79% examples, 271205 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:53 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 74.79% examples, 273682 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:54 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 78.67% examples, 275591 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:55 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 82.79% examples, 278006 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:56 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 86.91% examples, 280150 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:57 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 91.03% examples, 282338 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:58 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 95.03% examples, 284050 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:16:59 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 99.15% examples, 285762 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:00 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:17:00 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:17:00 gensim.models.word2vec INFO     EPOCH - 1 : training on 8250000 raw words (8250000 effective words) took 28.8s, 286027 effective words/s\n",
      "02-26 23:17:01 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 4.00% examples, 317044 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:02 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 8.12% examples, 326903 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:03 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 12.24% examples, 328608 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:04 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 16.36% examples, 330655 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:05 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 20.48% examples, 330616 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:06 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 24.61% examples, 331307 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:07 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 28.73% examples, 331228 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:08 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 32.85% examples, 331502 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:09 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 36.97% examples, 331359 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:10 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 41.09% examples, 331175 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:17:11 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 45.21% examples, 330770 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:12 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 49.33% examples, 330799 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:13 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 53.45% examples, 331070 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:14 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 57.58% examples, 331323 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:15 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 61.70% examples, 331632 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:17:16 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 65.94% examples, 332560 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:17 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 70.06% examples, 332761 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:18 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 74.06% examples, 331954 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:19 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 78.18% examples, 332239 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:20 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 82.30% examples, 332398 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:21 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 86.42% examples, 332705 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:22 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 90.55% examples, 332784 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:23 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 94.67% examples, 332670 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:24 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 98.79% examples, 332783 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:24 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:17:24 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:17:24 gensim.models.word2vec INFO     EPOCH - 2 : training on 8250000 raw words (8250000 effective words) took 24.8s, 332778 effective words/s\n",
      "02-26 23:17:25 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 4.00% examples, 322828 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:26 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 8.24% examples, 335502 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:27 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 12.36% examples, 335890 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:28 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 16.36% examples, 334095 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:30 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 20.48% examples, 332582 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:31 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 24.61% examples, 332676 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:32 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 28.73% examples, 333276 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:33 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 32.85% examples, 334045 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:34 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 36.97% examples, 334090 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:35 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 41.09% examples, 334283 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:36 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 45.45% examples, 335430 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:37 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 49.45% examples, 334966 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:38 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 53.70% examples, 334972 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:39 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 58.06% examples, 335649 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:17:40 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 62.18% examples, 335885 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:41 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 66.30% examples, 336110 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:42 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 70.42% examples, 336313 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:43 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 74.55% examples, 336104 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:44 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 78.67% examples, 336044 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:45 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 82.79% examples, 336204 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:46 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 87.03% examples, 336723 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:47 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 91.15% examples, 336696 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:48 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 95.39% examples, 336660 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:49 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 99.52% examples, 336793 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:49 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:17:49 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:17:49 gensim.models.word2vec INFO     EPOCH - 3 : training on 8250000 raw words (8250000 effective words) took 24.5s, 336698 effective words/s\n",
      "02-26 23:17:50 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 4.00% examples, 322921 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:51 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 8.12% examples, 330117 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:17:52 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 12.24% examples, 333151 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:17:53 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 16.61% examples, 335419 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:54 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 20.73% examples, 335811 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:55 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 24.85% examples, 333708 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:56 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 29.21% examples, 335483 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:57 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 33.58% examples, 336341 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:58 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 37.70% examples, 336696 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:17:59 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 41.82% examples, 336778 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:00 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 46.06% examples, 337661 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:01 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 50.06% examples, 336729 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:02 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 54.30% examples, 337346 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:03 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 58.42% examples, 337504 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:04 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 62.55% examples, 337533 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:05 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 66.67% examples, 337429 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:06 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 70.79% examples, 337297 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:07 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 74.91% examples, 337233 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:08 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 79.15% examples, 337308 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:09 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 83.27% examples, 337413 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:10 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 87.39% examples, 337167 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:11 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 91.39% examples, 336451 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:12 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 95.64% examples, 336760 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:13 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 99.88% examples, 336919 words/s, in_qsize 1, out_qsize 1\n",
      "02-26 23:18:13 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:18:13 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:18:13 gensim.models.word2vec INFO     EPOCH - 4 : training on 8250000 raw words (8250000 effective words) took 24.5s, 336953 effective words/s\n",
      "02-26 23:18:14 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 4.24% examples, 335673 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:16 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 8.61% examples, 339393 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:17 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 12.97% examples, 342556 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:18 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 17.09% examples, 339862 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:19 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 21.45% examples, 339884 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:20 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 25.70% examples, 341082 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:21 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 29.82% examples, 340472 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:22 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 33.94% examples, 339869 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:23 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 38.06% examples, 339598 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:24 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 42.06% examples, 338594 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:25 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 46.18% examples, 338557 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:26 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 50.30% examples, 338290 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:27 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 54.55% examples, 338924 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:28 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 58.67% examples, 338530 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:29 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 62.79% examples, 338514 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:30 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 66.67% examples, 337087 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:31 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 70.79% examples, 337144 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:18:32 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 74.91% examples, 337197 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:33 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 79.15% examples, 337645 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:34 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 83.27% examples, 337210 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:35 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 87.52% examples, 337536 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:36 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 91.64% examples, 337566 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:37 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 95.88% examples, 337853 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 100.00% examples, 337612 words/s, in_qsize 0, out_qsize 1\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     EPOCH - 5 : training on 8250000 raw words (8250000 effective words) took 24.4s, 337596 effective words/s\n",
      "02-26 23:18:38 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training on 41250000 raw words (41250000 effective words) took 127.1s, 324599 effective words/s', 'datetime': '2022-02-26T23:18:38.384494', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:18:38 gensim.utils INFO     Word2Vec lifecycle event {'params': 'Word2Vec(vocab=8250, vector_size=256, alpha=0.025)', 'datetime': '2022-02-26T23:18:38.385239', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "02-26 23:18:38 gensim.utils INFO     Word2Vec lifecycle event {'fname_or_handle': '/Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_256D.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-02-26T23:18:38.387270', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "02-26 23:18:38 gensim.utils INFO     not storing attribute cum_table\n",
      "02-26 23:18:38 gensim.utils INFO     saved /Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_256D.model\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     collecting all words and their counts\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     PROGRESS: at sentence #10000, processed 1000000 words, keeping 8134 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful save of model: corpus_2018_referral_sites_lvl_one_unweighted_256D.model!\n",
      "512 corpus_2018_referral_sites_lvl_one_unweighted_512D.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:18:38 gensim.models.word2vec INFO     PROGRESS: at sentence #20000, processed 2000000 words, keeping 8250 word types\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     PROGRESS: at sentence #30000, processed 3000000 words, keeping 8250 word types\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     PROGRESS: at sentence #40000, processed 4000000 words, keeping 8250 word types\n",
      "02-26 23:18:38 gensim.models.word2vec INFO     PROGRESS: at sentence #50000, processed 5000000 words, keeping 8250 word types\n",
      "02-26 23:18:39 gensim.models.word2vec INFO     PROGRESS: at sentence #60000, processed 6000000 words, keeping 8250 word types\n",
      "02-26 23:18:39 gensim.models.word2vec INFO     PROGRESS: at sentence #70000, processed 7000000 words, keeping 8250 word types\n",
      "02-26 23:18:39 gensim.models.word2vec INFO     PROGRESS: at sentence #80000, processed 8000000 words, keeping 8250 word types\n",
      "02-26 23:18:39 gensim.models.word2vec INFO     collected 8250 word types from a corpus of 8250000 raw words and 82500 sentences\n",
      "02-26 23:18:39 gensim.models.word2vec INFO     Creating a fresh vocabulary\n",
      "02-26 23:18:39 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 8250 unique words (100.0%% of original 8250, drops 0)', 'datetime': '2022-02-26T23:18:39.351512', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:18:39 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 8250000 word corpus (100.0%% of original 8250000, drops 0)', 'datetime': '2022-02-26T23:18:39.352286', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:18:39 gensim.models.word2vec INFO     deleting the raw counts dictionary of 8250 items\n",
      "02-26 23:18:39 gensim.models.word2vec INFO     sample=0.001 downsamples 0 most-common words\n",
      "02-26 23:18:39 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8250000 word corpus (100.0%% of prior 8250000)', 'datetime': '2022-02-26T23:18:39.410941', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:18:39 gensim.models.word2vec INFO     estimated required memory for 8250 words and 512 dimensions: 37917000 bytes\n",
      "02-26 23:18:39 gensim.models.word2vec INFO     resetting layer weights\n",
      "02-26 23:18:39 gensim.utils INFO     Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-02-26T23:18:39.528066', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "02-26 23:18:39 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training model with 2 workers on 8250 vocabulary and 512 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-02-26T23:18:39.529116', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:18:40 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 1.82% examples, 135035 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:41 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 3.76% examples, 141093 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:42 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 5.82% examples, 149145 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:18:43 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 7.64% examples, 147587 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:44 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 9.58% examples, 149908 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:45 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 11.52% examples, 150776 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:46 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 13.70% examples, 152431 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:47 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 15.76% examples, 154455 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:18:49 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 18.06% examples, 156861 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:50 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 20.48% examples, 160160 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:51 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 22.91% examples, 162889 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:52 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 25.33% examples, 165342 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:53 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 27.76% examples, 167463 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:54 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 30.18% examples, 169505 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:55 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 32.61% examples, 170660 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:56 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 35.15% examples, 172882 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:57 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 37.58% examples, 174373 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:58 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 40.12% examples, 175544 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:18:59 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 42.67% examples, 177277 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:00 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 45.09% examples, 178346 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:01 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 47.64% examples, 179178 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:02 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 50.30% examples, 180226 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:03 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 52.97% examples, 181244 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:19:04 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 55.64% examples, 182385 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:05 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 58.30% examples, 183326 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:06 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 60.97% examples, 184298 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:07 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 63.64% examples, 185175 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:08 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 66.30% examples, 186107 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:09 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 68.97% examples, 186924 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:11 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 71.64% examples, 187755 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:19:12 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 74.30% examples, 188430 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:13 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 76.97% examples, 189109 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:14 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 79.64% examples, 189794 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:15 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 82.30% examples, 190440 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:16 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 84.97% examples, 191036 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:17 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 87.64% examples, 191691 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:18 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 90.30% examples, 192215 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:19 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 92.97% examples, 192564 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:20 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 95.64% examples, 193007 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:21 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 98.30% examples, 193506 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:22 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:19:22 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:19:22 gensim.models.word2vec INFO     EPOCH - 1 : training on 8250000 raw words (8250000 effective words) took 42.6s, 193754 effective words/s\n",
      "02-26 23:19:23 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 2.55% examples, 205621 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:24 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 5.21% examples, 209986 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:25 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 7.88% examples, 211563 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:26 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 10.55% examples, 212551 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:27 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 13.21% examples, 213554 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:28 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 15.88% examples, 212995 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:29 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 18.55% examples, 213379 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:30 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 21.21% examples, 213369 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:31 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 23.88% examples, 213502 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:32 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 26.55% examples, 213758 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:33 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 29.21% examples, 213742 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:34 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 31.88% examples, 213821 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:35 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 34.55% examples, 213743 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:36 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 37.21% examples, 213826 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:37 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 39.88% examples, 213945 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:38 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 42.55% examples, 214034 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:39 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 45.21% examples, 214097 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:40 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 47.88% examples, 214136 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:41 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 50.55% examples, 214205 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:42 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 53.21% examples, 214327 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:43 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 55.88% examples, 214376 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:44 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 58.42% examples, 214010 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:45 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 61.09% examples, 214093 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:46 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 63.76% examples, 213952 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:47 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 66.42% examples, 214018 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:48 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 69.09% examples, 214125 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:49 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 71.76% examples, 214220 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:50 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 74.42% examples, 214353 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:51 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 77.09% examples, 214429 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:52 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 79.76% examples, 214541 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:53 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 82.42% examples, 214685 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:54 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 85.09% examples, 214797 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:55 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 87.76% examples, 214812 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:56 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 90.42% examples, 214846 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:57 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 93.09% examples, 214912 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:58 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 95.76% examples, 215011 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:19:59 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 98.42% examples, 215021 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:00 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:20:00 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:20:00 gensim.models.word2vec INFO     EPOCH - 2 : training on 8250000 raw words (8250000 effective words) took 38.3s, 215257 effective words/s\n",
      "02-26 23:20:01 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 2.55% examples, 200795 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:02 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 5.21% examples, 208373 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:03 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 7.88% examples, 207684 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:04 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 10.55% examples, 210162 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:05 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 13.21% examples, 211861 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:06 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 15.88% examples, 211682 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:07 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 18.55% examples, 212481 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:08 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 21.21% examples, 213111 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:09 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 23.88% examples, 213479 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:10 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 26.55% examples, 213831 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:11 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 29.21% examples, 214014 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:12 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 31.88% examples, 214283 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:13 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 34.55% examples, 214629 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:14 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 37.21% examples, 214952 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:15 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 39.88% examples, 215028 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:16 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 42.55% examples, 215156 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:17 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 45.21% examples, 215332 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:18 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 47.88% examples, 215506 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:19 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 50.55% examples, 215548 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:20 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 53.21% examples, 215670 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:21 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 55.88% examples, 215758 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:22 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 58.55% examples, 215904 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:23 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 61.21% examples, 216013 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:24 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 63.88% examples, 215996 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:25 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 66.42% examples, 215051 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:26 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 68.61% examples, 213660 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:27 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 70.67% examples, 212062 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:28 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 72.73% examples, 210569 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:29 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 74.79% examples, 208825 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:31 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 76.97% examples, 207447 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:32 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 79.39% examples, 206779 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:33 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 81.82% examples, 206121 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:34 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 84.24% examples, 205916 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:35 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 86.91% examples, 206009 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:36 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 89.58% examples, 206351 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:37 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 92.24% examples, 206531 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:38 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 95.03% examples, 207017 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:39 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 97.58% examples, 207009 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:40 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:20:40 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:20:40 gensim.models.word2vec INFO     EPOCH - 3 : training on 8250000 raw words (8250000 effective words) took 39.8s, 207280 effective words/s\n",
      "02-26 23:20:41 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 2.30% examples, 185574 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:42 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 4.97% examples, 201443 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:43 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 7.64% examples, 205722 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:44 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 10.30% examples, 208927 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:45 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 12.97% examples, 210268 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:46 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 15.64% examples, 211125 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:47 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 18.30% examples, 211614 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:48 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 20.97% examples, 212388 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:49 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 23.64% examples, 212486 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:50 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 26.30% examples, 212904 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:20:51 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 28.97% examples, 213355 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:52 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 31.64% examples, 213754 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:20:53 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 34.30% examples, 213992 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:54 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 36.97% examples, 213810 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:55 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 39.64% examples, 213981 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:56 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 42.30% examples, 214062 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:57 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 44.97% examples, 214355 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:20:58 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 47.64% examples, 214579 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:20:59 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 50.30% examples, 214688 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:00 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 52.85% examples, 214218 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:01 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 55.52% examples, 214323 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:02 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 58.18% examples, 214474 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:03 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 60.85% examples, 214651 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:04 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 63.52% examples, 214800 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:05 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 66.06% examples, 214562 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:06 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 68.73% examples, 214678 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:07 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 71.39% examples, 214553 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:08 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 74.06% examples, 214676 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:09 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 76.73% examples, 214801 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:10 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 79.39% examples, 214720 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:11 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 82.06% examples, 214483 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:12 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 84.73% examples, 214569 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:13 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 87.39% examples, 214595 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:14 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 90.06% examples, 214709 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:15 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 92.73% examples, 214745 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:16 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 95.39% examples, 214614 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:17 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 98.06% examples, 214569 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:18 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:21:18 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:21:18 gensim.models.word2vec INFO     EPOCH - 4 : training on 8250000 raw words (8250000 effective words) took 38.4s, 214612 effective words/s\n",
      "02-26 23:21:19 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 2.55% examples, 204764 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:20 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 5.21% examples, 208977 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:21 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 7.88% examples, 211512 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:22 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 10.55% examples, 210212 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:23 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 13.21% examples, 211270 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:24 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 15.88% examples, 211612 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:25 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 18.55% examples, 212169 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:26 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 21.21% examples, 212703 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:27 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 23.88% examples, 213400 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:28 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 26.42% examples, 212873 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:29 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 28.97% examples, 212067 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:30 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 31.64% examples, 212261 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:32 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 34.30% examples, 212501 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:33 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 36.97% examples, 212719 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:34 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 39.64% examples, 212988 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:35 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 42.30% examples, 212749 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:36 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 44.97% examples, 212936 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:37 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 47.64% examples, 213002 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:38 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 50.30% examples, 213140 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:39 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 52.97% examples, 213176 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:40 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 55.27% examples, 211988 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:41 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 57.45% examples, 210452 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:42 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 59.76% examples, 209543 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:43 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 62.42% examples, 209602 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:44 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 65.09% examples, 209918 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:45 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 67.76% examples, 210112 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:46 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 70.42% examples, 210364 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:47 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 73.09% examples, 210560 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:48 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 75.76% examples, 210729 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:49 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 78.42% examples, 210966 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:50 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 81.09% examples, 211133 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:51 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 83.76% examples, 211271 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:52 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 86.42% examples, 211403 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:53 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 88.61% examples, 210318 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:54 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 90.55% examples, 208730 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:55 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 92.73% examples, 207679 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:56 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 94.91% examples, 206754 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:57 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 97.33% examples, 206141 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:21:58 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 99.76% examples, 205701 words/s, in_qsize 2, out_qsize 0\n",
      "02-26 23:21:58 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:21:58 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:21:58 gensim.models.word2vec INFO     EPOCH - 5 : training on 8250000 raw words (8250000 effective words) took 40.1s, 205642 effective words/s\n",
      "02-26 23:21:58 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training on 41250000 raw words (41250000 effective words) took 199.3s, 206985 effective words/s', 'datetime': '2022-02-26T23:21:58.823303', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:21:58 gensim.utils INFO     Word2Vec lifecycle event {'params': 'Word2Vec(vocab=8250, vector_size=512, alpha=0.025)', 'datetime': '2022-02-26T23:21:58.824057', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "02-26 23:21:58 gensim.utils INFO     Word2Vec lifecycle event {'fname_or_handle': '/Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_512D.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-02-26T23:21:58.825009', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "02-26 23:21:58 gensim.utils INFO     not storing attribute cum_table\n",
      "02-26 23:21:58 gensim.utils INFO     saved /Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_512D.model\n",
      "02-26 23:21:58 gensim.models.word2vec INFO     collecting all words and their counts\n",
      "02-26 23:21:58 gensim.models.word2vec INFO     PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "02-26 23:21:58 gensim.models.word2vec INFO     PROGRESS: at sentence #10000, processed 1000000 words, keeping 8134 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful save of model: corpus_2018_referral_sites_lvl_one_unweighted_512D.model!\n",
      "1024 corpus_2018_referral_sites_lvl_one_unweighted_1024D.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:21:59 gensim.models.word2vec INFO     PROGRESS: at sentence #20000, processed 2000000 words, keeping 8250 word types\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     PROGRESS: at sentence #30000, processed 3000000 words, keeping 8250 word types\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     PROGRESS: at sentence #40000, processed 4000000 words, keeping 8250 word types\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     PROGRESS: at sentence #50000, processed 5000000 words, keeping 8250 word types\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     PROGRESS: at sentence #60000, processed 6000000 words, keeping 8250 word types\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     PROGRESS: at sentence #70000, processed 7000000 words, keeping 8250 word types\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     PROGRESS: at sentence #80000, processed 8000000 words, keeping 8250 word types\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     collected 8250 word types from a corpus of 8250000 raw words and 82500 sentences\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     Creating a fresh vocabulary\n",
      "02-26 23:21:59 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 8250 unique words (100.0%% of original 8250, drops 0)', 'datetime': '2022-02-26T23:21:59.796573', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:21:59 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 8250000 word corpus (100.0%% of original 8250000, drops 0)', 'datetime': '2022-02-26T23:21:59.797287', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     deleting the raw counts dictionary of 8250 items\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     sample=0.001 downsamples 0 most-common words\n",
      "02-26 23:21:59 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8250000 word corpus (100.0%% of prior 8250000)', 'datetime': '2022-02-26T23:21:59.849515', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     estimated required memory for 8250 words and 1024 dimensions: 71709000 bytes\n",
      "02-26 23:21:59 gensim.models.word2vec INFO     resetting layer weights\n",
      "02-26 23:21:59 gensim.utils INFO     Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-02-26T23:21:59.970787', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "02-26 23:21:59 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training model with 2 workers on 8250 vocabulary and 1024 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-02-26T23:21:59.971470', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:22:01 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 1.09% examples, 82126 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:02 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 2.30% examples, 87881 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:03 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 3.52% examples, 90540 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:04 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 4.73% examples, 92515 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:05 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 6.06% examples, 94802 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:06 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 7.39% examples, 95335 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:07 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 8.73% examples, 96993 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:08 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 10.06% examples, 97488 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:09 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 11.52% examples, 98591 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:10 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 12.97% examples, 99739 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:11 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 14.42% examples, 100567 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:12 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 15.88% examples, 101525 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:13 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 17.33% examples, 102488 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:14 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 18.67% examples, 102899 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:16 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 20.12% examples, 103584 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:17 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 21.58% examples, 103831 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:18 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 23.03% examples, 104445 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:19 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 24.48% examples, 105045 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:20 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 25.94% examples, 105626 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:21 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 27.39% examples, 106234 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:22 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 28.85% examples, 106834 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:23 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 30.06% examples, 106501 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:24 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 31.52% examples, 106239 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:25 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 32.85% examples, 106231 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:26 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 34.18% examples, 106335 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:27 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 35.52% examples, 106379 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:28 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 37.09% examples, 106980 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:29 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 38.67% examples, 107442 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:30 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 40.00% examples, 107448 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:31 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 41.33% examples, 107245 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:32 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 42.79% examples, 107319 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:33 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 44.24% examples, 107478 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:35 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 45.94% examples, 107912 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:36 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 47.64% examples, 108383 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:37 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 49.33% examples, 108873 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:38 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 51.03% examples, 109330 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:39 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 52.73% examples, 109781 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:40 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 54.18% examples, 109948 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:41 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 55.88% examples, 110391 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:42 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 57.58% examples, 110862 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:43 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 59.15% examples, 111281 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:44 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 60.73% examples, 111640 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:45 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 62.30% examples, 111982 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:46 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 63.88% examples, 112269 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:47 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 65.45% examples, 112511 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:49 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 67.15% examples, 112846 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:22:50 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 68.85% examples, 113162 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:51 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 70.55% examples, 113404 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:52 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 72.24% examples, 113671 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:53 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 73.94% examples, 113998 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:54 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 75.64% examples, 114289 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:55 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 77.33% examples, 114605 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:56 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 79.03% examples, 114814 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:57 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 80.73% examples, 115107 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:58 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 82.42% examples, 115356 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:22:59 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 84.00% examples, 115594 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:00 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 85.58% examples, 115768 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:02 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 87.03% examples, 115716 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:03 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 88.36% examples, 115539 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:04 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 89.82% examples, 115551 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:05 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 91.27% examples, 115524 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:23:06 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 92.85% examples, 115673 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:07 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 94.42% examples, 115856 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:08 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 96.12% examples, 116082 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:09 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 97.82% examples, 116265 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:10 gensim.models.word2vec INFO     EPOCH 1 - PROGRESS: at 99.52% examples, 116465 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:10 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:23:10 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:23:10 gensim.models.word2vec INFO     EPOCH - 1 : training on 8250000 raw words (8250000 effective words) took 70.8s, 116526 effective words/s\n",
      "02-26 23:23:11 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 1.58% examples, 121403 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:12 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 3.27% examples, 126310 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:13 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 4.97% examples, 127765 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:15 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 6.67% examples, 128293 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:16 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 8.12% examples, 123859 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:23:17 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 8.61% examples, 110345 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:18 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 10.06% examples, 110804 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:23:19 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 11.52% examples, 111472 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:20 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 13.21% examples, 113295 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:21 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 14.91% examples, 115262 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:22 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 16.61% examples, 116913 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:23 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 18.30% examples, 118219 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:24 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 20.00% examples, 119328 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:25 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 21.70% examples, 120045 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:26 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 23.39% examples, 120958 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:27 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 25.09% examples, 121658 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:28 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 26.79% examples, 122206 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:29 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 28.48% examples, 122535 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:31 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 30.18% examples, 123055 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:32 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 31.88% examples, 123445 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:33 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 33.58% examples, 123664 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:34 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 35.27% examples, 124041 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:35 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 36.97% examples, 124427 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:36 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 38.67% examples, 124688 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:37 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 40.36% examples, 125044 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:38 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 42.06% examples, 125341 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:39 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 43.76% examples, 125649 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:40 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 45.45% examples, 125890 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:23:41 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 47.15% examples, 126180 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:42 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 48.85% examples, 126408 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:43 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 50.55% examples, 126661 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:44 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 52.24% examples, 126799 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:45 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 53.94% examples, 127020 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:46 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 55.64% examples, 127192 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:47 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 57.33% examples, 127339 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:48 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 59.03% examples, 127509 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:50 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 60.73% examples, 127643 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:51 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 62.42% examples, 127552 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:52 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 63.88% examples, 127213 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:53 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 65.58% examples, 127279 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:54 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 67.27% examples, 127447 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:55 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 68.73% examples, 127244 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:56 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 70.18% examples, 127055 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:57 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 71.88% examples, 126979 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:58 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 73.58% examples, 126995 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:23:59 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 75.27% examples, 127235 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:00 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 76.97% examples, 127476 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:01 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 78.67% examples, 127720 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:02 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 80.36% examples, 127948 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:03 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 82.18% examples, 128359 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:04 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 83.76% examples, 128386 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:05 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 85.45% examples, 128356 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:06 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 87.15% examples, 128272 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:07 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 88.85% examples, 128187 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:09 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 90.55% examples, 128287 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:10 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 92.24% examples, 128423 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:11 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 93.94% examples, 128610 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:12 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 95.64% examples, 128720 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:13 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 97.33% examples, 128783 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:14 gensim.models.word2vec INFO     EPOCH 2 - PROGRESS: at 99.03% examples, 128958 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:14 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:24:14 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:24:14 gensim.models.word2vec INFO     EPOCH - 2 : training on 8250000 raw words (8250000 effective words) took 64.0s, 128984 effective words/s\n",
      "02-26 23:24:15 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 1.58% examples, 121861 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:16 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 3.39% examples, 134092 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:17 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 5.09% examples, 134509 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:18 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 6.79% examples, 135680 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:19 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 8.36% examples, 133036 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:20 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 10.06% examples, 132859 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:22 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 11.76% examples, 132960 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:23 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 13.45% examples, 133536 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:24 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 15.15% examples, 134022 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:25 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 16.85% examples, 134092 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:26 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 18.55% examples, 134075 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:27 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 20.24% examples, 134151 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:28 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 21.94% examples, 134021 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:29 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 23.52% examples, 133567 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:30 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 25.09% examples, 132962 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:31 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 26.79% examples, 133120 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:32 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 28.48% examples, 133404 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:33 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 30.18% examples, 133703 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:34 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 31.88% examples, 133911 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:35 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 33.58% examples, 134110 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:36 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 35.27% examples, 134060 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:37 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 36.97% examples, 134154 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:38 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 38.55% examples, 133883 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:39 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 40.00% examples, 133079 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:40 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 41.33% examples, 132161 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:41 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 42.91% examples, 131578 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:24:42 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 44.36% examples, 130822 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:43 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 46.06% examples, 130478 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:24:44 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 47.64% examples, 130461 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:45 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 49.33% examples, 130741 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:46 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 50.91% examples, 130288 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:24:48 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 52.85% examples, 130669 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:49 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 54.79% examples, 131019 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:50 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 56.73% examples, 131389 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:51 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 58.55% examples, 131873 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:52 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 60.36% examples, 131952 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:53 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 62.06% examples, 131840 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:54 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 63.88% examples, 132252 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:55 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 65.45% examples, 132022 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:56 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 67.27% examples, 132352 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:57 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 68.85% examples, 132195 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:24:58 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 70.55% examples, 132117 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:24:59 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 72.24% examples, 132078 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:25:00 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 73.70% examples, 131720 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:01 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 75.27% examples, 131635 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:02 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 76.85% examples, 131421 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:04 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 78.55% examples, 131434 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:05 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 80.12% examples, 131226 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:06 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 81.58% examples, 130827 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:07 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 83.03% examples, 130602 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:08 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 84.61% examples, 130496 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:09 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 86.30% examples, 130591 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:10 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 87.88% examples, 130555 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:11 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 89.58% examples, 130635 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:12 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 91.27% examples, 130685 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:13 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 92.97% examples, 130745 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:14 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 94.67% examples, 130792 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:15 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 96.36% examples, 130843 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:16 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 98.06% examples, 130844 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:17 gensim.models.word2vec INFO     EPOCH 3 - PROGRESS: at 99.76% examples, 130910 words/s, in_qsize 2, out_qsize 0\n",
      "02-26 23:25:17 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:25:17 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:25:17 gensim.models.word2vec INFO     EPOCH - 3 : training on 8250000 raw words (8250000 effective words) took 63.0s, 130933 effective words/s\n",
      "02-26 23:25:18 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 1.58% examples, 123169 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:19 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 3.27% examples, 128514 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:20 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 4.97% examples, 130747 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:21 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 6.42% examples, 126563 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:22 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 7.76% examples, 123093 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:25:24 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 9.09% examples, 120112 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:25 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 10.55% examples, 120038 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:26 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 12.24% examples, 120775 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:27 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 13.94% examples, 122423 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:28 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 15.64% examples, 123497 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:29 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 17.33% examples, 124573 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:30 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 19.03% examples, 125385 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:25:31 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 20.73% examples, 126121 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:32 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 22.42% examples, 126567 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:33 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 24.12% examples, 127181 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:34 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 25.82% examples, 127594 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:35 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 27.52% examples, 127896 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:36 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 29.21% examples, 128283 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:37 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 30.91% examples, 128551 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:38 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 32.61% examples, 128819 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:39 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 34.30% examples, 129079 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:40 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 36.00% examples, 129336 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:41 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 37.70% examples, 129562 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:42 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 39.39% examples, 129727 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:43 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 41.09% examples, 129966 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:44 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 42.79% examples, 130098 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:45 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 44.48% examples, 130272 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:46 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 46.18% examples, 130429 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:48 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 47.88% examples, 130621 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:49 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 49.45% examples, 130549 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:50 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 51.15% examples, 130679 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:51 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 52.85% examples, 130769 words/s, in_qsize 4, out_qsize 1\n",
      "02-26 23:25:52 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 54.55% examples, 130933 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:53 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 56.24% examples, 131029 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:54 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 57.94% examples, 131128 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:55 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 59.64% examples, 131253 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:56 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 61.33% examples, 131317 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:57 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 63.03% examples, 131398 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:58 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 64.73% examples, 131495 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:25:59 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 66.42% examples, 131458 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:00 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 68.12% examples, 131520 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:01 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 69.82% examples, 131575 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:02 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 71.52% examples, 131643 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:03 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 73.21% examples, 131709 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:04 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 74.91% examples, 131735 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:05 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 76.48% examples, 131639 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:06 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 78.18% examples, 131697 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:07 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 79.88% examples, 131718 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:08 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 81.58% examples, 131441 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:10 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 82.79% examples, 130700 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:11 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 84.24% examples, 130487 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:12 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 85.70% examples, 130281 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:13 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 87.39% examples, 130367 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:14 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 89.09% examples, 130420 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:15 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 90.79% examples, 130507 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:16 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 92.48% examples, 130568 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:17 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 94.18% examples, 130652 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:18 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 95.88% examples, 130670 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:19 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 97.58% examples, 130765 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:20 gensim.models.word2vec INFO     EPOCH 4 - PROGRESS: at 99.27% examples, 130814 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:20 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:26:20 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:26:20 gensim.models.word2vec INFO     EPOCH - 4 : training on 8250000 raw words (8250000 effective words) took 63.1s, 130847 effective words/s\n",
      "02-26 23:26:21 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 1.58% examples, 124519 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:22 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 3.27% examples, 126238 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:24 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 4.97% examples, 128369 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:25 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 6.67% examples, 129539 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:26 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 8.36% examples, 130508 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:27 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 10.06% examples, 130748 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:28 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 11.76% examples, 131520 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:26:29 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 13.45% examples, 132207 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:30 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 15.15% examples, 132584 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:31 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 16.85% examples, 132503 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:32 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 18.55% examples, 132682 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:33 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 20.24% examples, 132677 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:34 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 21.94% examples, 132860 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:35 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 23.64% examples, 132808 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:36 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 25.33% examples, 132720 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:37 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 27.03% examples, 132571 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:38 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 28.73% examples, 132300 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:26:39 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 30.42% examples, 132337 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:40 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 32.00% examples, 132020 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:41 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 32.85% examples, 128931 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:43 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 34.30% examples, 127115 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:44 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 35.15% examples, 123971 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:45 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 36.61% examples, 123680 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:46 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 38.06% examples, 123415 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:47 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 39.52% examples, 123210 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:48 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 41.21% examples, 123554 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:49 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 42.79% examples, 123668 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:50 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 44.48% examples, 124026 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:51 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 46.18% examples, 124348 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:52 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 47.88% examples, 124655 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:53 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 49.58% examples, 124930 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:54 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 51.27% examples, 125226 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:55 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 52.97% examples, 125398 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:56 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 54.67% examples, 125657 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:57 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 56.36% examples, 125862 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:26:58 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 58.06% examples, 126129 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:26:59 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 59.64% examples, 126221 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:00 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 61.33% examples, 126386 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:01 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 63.03% examples, 126527 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:02 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 64.73% examples, 126709 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:04 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 66.42% examples, 126858 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:05 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 68.12% examples, 127039 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:06 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 69.82% examples, 127196 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:07 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 71.52% examples, 127314 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:08 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 73.21% examples, 127461 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:09 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 74.91% examples, 127640 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:10 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 76.48% examples, 127678 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:11 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 78.18% examples, 127840 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:12 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 79.88% examples, 127938 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:13 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 81.58% examples, 128053 words/s, in_qsize 4, out_qsize 0\n",
      "02-26 23:27:14 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 83.27% examples, 128185 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:15 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 84.97% examples, 128324 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:16 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 86.67% examples, 128437 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:17 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 88.36% examples, 128552 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:18 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 90.06% examples, 128643 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:19 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 91.76% examples, 128753 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:20 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 93.33% examples, 128766 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:21 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 95.03% examples, 128815 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:22 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 96.73% examples, 128892 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:23 gensim.models.word2vec INFO     EPOCH 5 - PROGRESS: at 98.42% examples, 128975 words/s, in_qsize 3, out_qsize 0\n",
      "02-26 23:27:24 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 1 more threads\n",
      "02-26 23:27:24 gensim.models.word2vec INFO     worker thread finished; awaiting finish of 0 more threads\n",
      "02-26 23:27:24 gensim.models.word2vec INFO     EPOCH - 5 : training on 8250000 raw words (8250000 effective words) took 63.9s, 129017 effective words/s\n",
      "02-26 23:27:24 gensim.utils INFO     Word2Vec lifecycle event {'msg': 'training on 41250000 raw words (41250000 effective words) took 324.8s, 127006 effective words/s', 'datetime': '2022-02-26T23:27:24.764483', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "02-26 23:27:24 gensim.utils INFO     Word2Vec lifecycle event {'params': 'Word2Vec(vocab=8250, vector_size=1024, alpha=0.025)', 'datetime': '2022-02-26T23:27:24.765107', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "02-26 23:27:24 gensim.utils INFO     Word2Vec lifecycle event {'fname_or_handle': '/Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_1024D.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-02-26T23:27:24.766425', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 06:23:56) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "02-26 23:27:24 gensim.utils INFO     not storing attribute cum_table\n",
      "02-26 23:27:24 gensim.utils INFO     saved /Users/panayot/Documents/News-Media-Peers/models/corpus_2018_referral_sites_lvl_one_unweighted_1024D.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful save of model: corpus_2018_referral_sites_lvl_one_unweighted_1024D.model!\n"
     ]
    }
   ],
   "source": [
    "models = create_node2vec_model(G, dimensions=[64, 128, 256, 512, 1024], is_weighted=False,\n",
    "                               prefix='corpus_2018_referral_sites_lvl_one')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export embeddings as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: corpus_2018_referral_sites_lvl_one_unweighted_64D.model\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                        |\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_64D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:27:26 train        INFO     Start training...\n",
      "02-26 23:27:26 train        INFO     Fold: 0\n",
      "02-26 23:27:30 train        INFO     Fold: 1\n",
      "02-26 23:27:34 train        INFO     Fold: 2\n",
      "02-26 23:27:37 train        INFO     Fold: 3\n",
      "02-26 23:27:41 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+------------------+-------------------+-------------------+---------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                        |     Macro-F1     |      Accuracy     |  Flip error-rate  |         MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+------------------+-------------------+-------------------+---------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_64D.model | 57.7683337679825 | 65.69274269557022 | 9.613572101790764 | 0.43920829406220546 |\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+------------------+-------------------+-------------------+---------------------+\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                        |\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_64D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:27:45 train        INFO     Start training...\n",
      "02-26 23:27:45 train        INFO     Fold: 0\n",
      "02-26 23:27:49 train        INFO     Fold: 1\n",
      "02-26 23:27:53 train        INFO     Fold: 2\n",
      "02-26 23:27:58 train        INFO     Fold: 3\n",
      "02-26 23:28:02 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+--------------------+-------------------+--------------------+---------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                        |      Macro-F1      |      Accuracy     |  Flip error-rate   |         MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+--------------------+-------------------+--------------------+---------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_64D.model | 59.772056045549334 | 67.86050895381716 | 4.0527803958529685 | 0.36192271442035817 |\n",
      "+------+-----------+---------------------+---------------+--------------------+---------------------------------------------------------+--------------------+-------------------+--------------------+---------------------+\n",
      "\n",
      " ================================================== \n",
      "\n",
      "Processing model: corpus_2018_referral_sites_lvl_one_unweighted_128D.model\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_128D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:28:08 train        INFO     Start training...\n",
      "02-26 23:28:08 train        INFO     Fold: 0\n",
      "02-26 23:28:13 train        INFO     Fold: 1\n",
      "02-26 23:28:17 train        INFO     Fold: 2\n",
      "02-26 23:28:21 train        INFO     Fold: 3\n",
      "02-26 23:28:25 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+-------------------+-------------------+--------------------+--------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |      Macro-F1     |      Accuracy     |  Flip error-rate   |        MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+-------------------+-------------------+--------------------+--------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_128D.model | 55.60247055263764 | 62.86522148916117 | 11.121583411875589 | 0.4825636192271442 |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+-------------------+-------------------+--------------------+--------------------+\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_128D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:28:29 train        INFO     Start training...\n",
      "02-26 23:28:29 train        INFO     Fold: 0\n",
      "02-26 23:28:34 train        INFO     Fold: 1\n",
      "02-26 23:28:38 train        INFO     Fold: 2\n",
      "02-26 23:28:43 train        INFO     Fold: 3\n",
      "02-26 23:28:49 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+------------------+-------------------+-------------------+---------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |     Macro-F1     |      Accuracy     |  Flip error-rate  |         MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+------------------+-------------------+-------------------+---------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_128D.model | 58.4423518071152 | 66.72950047125353 | 4.618284637134779 | 0.37888784165881245 |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+------------------+-------------------+-------------------+---------------------+\n",
      "\n",
      " ================================================== \n",
      "\n",
      "Processing model: corpus_2018_referral_sites_lvl_one_unweighted_256D.model\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_256D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:28:56 train        INFO     Start training...\n",
      "02-26 23:28:56 train        INFO     Fold: 0\n",
      "02-26 23:29:04 train        INFO     Fold: 1\n",
      "02-26 23:29:11 train        INFO     Fold: 2\n",
      "02-26 23:29:20 train        INFO     Fold: 3\n",
      "02-26 23:29:27 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+-------------------+-------------------+-------------------+---------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |      Macro-F1     |      Accuracy     |  Flip error-rate  |         MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+-------------------+-------------------+-------------------+---------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_256D.model | 57.36767775728001 | 64.09048067860509 | 9.048067860508954 | 0.44957587181903863 |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+-------------------+-------------------+-------------------+---------------------+\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_256D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:29:35 train        INFO     Start training...\n",
      "02-26 23:29:35 train        INFO     Fold: 0\n",
      "02-26 23:29:42 train        INFO     Fold: 1\n",
      "02-26 23:29:49 train        INFO     Fold: 2\n",
      "02-26 23:29:55 train        INFO     Fold: 3\n",
      "02-26 23:30:01 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+--------------------+-------------------+-------------------+--------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |      Macro-F1      |      Accuracy     |  Flip error-rate  |        MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+--------------------+-------------------+-------------------+--------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_256D.model | 59.321617309696876 | 66.16399622997172 | 4.429783223374175 | 0.3826578699340245 |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+--------------------+-------------------+-------------------+--------------------+\n",
      "\n",
      " ================================================== \n",
      "\n",
      "Processing model: corpus_2018_referral_sites_lvl_one_unweighted_512D.model\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_512D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:30:14 train        INFO     Start training...\n",
      "02-26 23:30:14 train        INFO     Fold: 0\n",
      "02-26 23:30:27 train        INFO     Fold: 1\n",
      "02-26 23:30:39 train        INFO     Fold: 2\n",
      "02-26 23:30:51 train        INFO     Fold: 3\n",
      "02-26 23:31:02 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+--------------------+-------------------+------------------+---------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |      Macro-F1      |      Accuracy     | Flip error-rate  |         MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+--------------------+-------------------+------------------+---------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_512D.model | 55.861470002020894 | 63.71347785108389 | 9.99057492931197 | 0.46277097078228085 |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+--------------------+-------------------+------------------+---------------------+\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_512D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:31:16 train        INFO     Start training...\n",
      "02-26 23:31:16 train        INFO     Fold: 0\n",
      "02-26 23:31:27 train        INFO     Fold: 1\n",
      "02-26 23:31:38 train        INFO     Fold: 2\n",
      "02-26 23:31:51 train        INFO     Fold: 3\n",
      "02-26 23:32:03 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                         features                         |      Macro-F1     |      Accuracy     |  Flip error-rate  |        MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_512D.model | 59.35164616085669 | 66.54099905749294 | 4.806786050895382 | 0.3826578699340245 |\n",
      "+------+-----------+---------------------+---------------+--------------------+----------------------------------------------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "\n",
      " ================================================== \n",
      "\n",
      "Processing model: corpus_2018_referral_sites_lvl_one_unweighted_1024D.model\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                          features                         |\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_1024D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:32:30 train        INFO     Start training...\n",
      "02-26 23:32:30 train        INFO     Fold: 0\n",
      "02-26 23:33:05 train        INFO     Fold: 1\n",
      "02-26 23:33:40 train        INFO     Fold: 2\n",
      "02-26 23:34:16 train        INFO     Fold: 3\n",
      "02-26 23:34:50 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                          features                         |      Macro-F1     |      Accuracy     |  Flip error-rate  |        MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "| fact | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_1024D.model | 55.31176776806834 | 62.67672007540056 | 9.048067860508954 | 0.4637134778510839 |\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                          features                         |\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_1024D.model |\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-26 23:35:31 train        INFO     Start training...\n",
      "02-26 23:35:31 train        INFO     Fold: 0\n",
      "02-26 23:36:05 train        INFO     Fold: 1\n",
      "02-26 23:36:39 train        INFO     Fold: 2\n",
      "02-26 23:37:13 train        INFO     Fold: 3\n",
      "02-26 23:37:48 train        INFO     Fold: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "| task |  dataset  | classification_mode | type_training | normalize_features |                          features                         |      Macro-F1     |      Accuracy     |  Flip error-rate  |        MAE         |\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "| bias | emnlp2018 |  single classifier  |    combine    |       False        | corpus_2018_referral_sites_lvl_one_unweighted_1024D.model | 59.20639616789962 | 66.54099905749294 | 4.806786050895382 | 0.3826578699340245 |\n",
      "+------+-----------+---------------------+---------------+--------------------+-----------------------------------------------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "\n",
      " ================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f'Processing model: {model_name}')\n",
    "    embeddings_wv = {site: model.wv.get_vector(site).tolist() for site in G.nodes()}\n",
    "    export_model_as_feature(embeddings_wv, model_name, data_year='2018')\n",
    "    run_experiment(features=model_name, dataset='emnlp2018', task='fact')\n",
    "    print('\\n', '-'*50, '\\n')\n",
    "    run_experiment(features=model_name, dataset='emnlp2018', task='bias')\n",
    "    print('\\n', '='*50, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "940b4c110c3cebababd37dc6cec19477a44e469d32c41a0eaa8eeb689ff0386b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('site_similarity': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "72b3faef5542ae75c34eb0d3b11ce0fc432eb00b9ccfc309dfbebb58f482608a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
