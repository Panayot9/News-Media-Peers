{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.nn import GNNExplainer\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborSampler #as RawNeighborSampler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch_cluster import random_walk\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def create_dataset(edges, features, labels, train_mask, test_mask):\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "    x = torch.tensor(features, dtype = torch.float)\n",
    "    y = torch.tensor(labels, dtype = torch.long)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index.t().contiguous(), y=y)\n",
    "    breakpoint\n",
    "    #supervised setting\n",
    "    if train_mask != None:\n",
    "        data.train_mask = torch.tensor(train_mask, dtype = torch.bool)\n",
    "        if test_mask == None:\n",
    "            data.test_mask = ~data.train_mask\n",
    "        \n",
    "    #semi-supervised setting\n",
    "    if test_mask != None:\n",
    "        data.test_mask = torch.tensor(test_mask, dtype = torch.bool)\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeigbourSampler return Bipartite graph so it will not be used, Neigborloader got the error of too many vlue to unpack so it is commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeighborLoaderX(NeighborLoader):\n",
    "#     def sample(self, batch):\n",
    "#         batch = torch.tensor(batch)\n",
    "#         row, col, _ = self.adj_t.coo()\n",
    "\n",
    "#         # For each node in `batch`, we sample a direct neighbor (as positive\n",
    "#         # example) and a random node (as negative example):\n",
    "#         pos_batch = random_walk(row, col, batch, walk_length=1,\n",
    "#                                 coalesced=False)[:, 1]\n",
    "\n",
    "#         neg_batch = torch.randint(0, self.adj_t.size(1), (batch.numel(), ),\n",
    "#                                   dtype=torch.long)\n",
    "\n",
    "#         batch = torch.cat([batch, pos_batch, neg_batch], dim=0)\n",
    "#         batch1 = super(NeighborLoaderX, self).sample(batch)\n",
    "#         return batch1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell will use outout_dim = 7 so input featurs would be compared with output in MSE as pos_batch, neg_batch is not working as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels,\n",
    "                 hidden_channels,\n",
    "                 out_dim,\n",
    "                 num_layers):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else hidden_channels\n",
    "            self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        # # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels), nn.Dropout(0.25), \n",
    "            nn.Linear(hidden_channels, out_dim))\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(data, hidden_channels = 128, num_layers = 3, batch_size = 256):\n",
    "    print(\"Entered prepare()\")\n",
    "    train_mask = torch.ones(10161, dtype=torch.bool)\n",
    "    # The NeighborLoader is called instead of NeighborLoaderX\n",
    "    train_loader = NeighborLoader(data, input_nodes=train_mask, num_neighbors=[10]*2,\n",
    "                            shuffle=True,  batch_size = 256)\n",
    "    print(\"train_loader= {}\".format(train_loader))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"#features = {}\".format(data.num_node_features))\n",
    "    #print(\"Num layers \", num_layers)\n",
    "    #The output_dim is provided\n",
    "    model = GCN(data.num_node_features, hidden_channels, 7, num_layers)\n",
    "    #model = GCN(data.num_node_features,64, 64)\n",
    "    #model = Encoder(data.num_node_features, 64)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    x, edge_index = data.x.to(device), data.edge_index.to(device)\n",
    "    return model, optimizer, x, edge_index, train_loader, device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is not confirmed that this loss function is worth-to-use but I could only run GCN in this way, if you can run GCN in PyG with Pos_batch and neg_bath, please let me know.\n",
    "#### According to my knowledge, randome_walk works with pairs thats why it returns bipartite graph but bipartitel input is not acceptble by GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, device):\n",
    "    print(\"Entered train()\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x.to(device), batch.edge_index.to(device))\n",
    "        # Compute the MSE loss\n",
    "        loss = F.mse_loss(out.to(device), batch.x.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #total_loss += float(loss) * out.size(0)\n",
    "        total_loss += float(loss)\n",
    "\n",
    "\n",
    "    return total_loss / data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(data, nepochs):\n",
    "    print(\"Entered train_all()\")\n",
    "    model, optimizer, x, edge_index, train_loader, device = prepare(data)\n",
    "    print(model)\n",
    "\n",
    "    for epoch in range(1, nepochs+1):\n",
    "        loss = train(model, optimizer, train_loader, device)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    return model, x, edge_index\n",
    "\n",
    "\n",
    "def predict_all(model, x, edge_index):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        #out = model.full_forward(x, edge_index).cpu()\n",
    "        out = model(x, edge_index).cpu()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, x, edge_index = train_all(data, 10)\n",
    "#The loss is very less so not sure that this loss is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "from notebooks.utils import _ALEXA_DATA_PATH, load_node_features, load_level_data, create_audience_overlap_nodes, export_model_as_feature\n",
    "from train import run_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-22 19:34:38 notebooks.utils INFO     Loaded 3489 nodes with records level <= 1 and child size:16981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('crooked.com', 'votesaveamerica.com'), ('crooked.com', 'art19.com'), ('crooked.com', 'promocodeportal.com'), ('crooked.com', 'mediamatters.org'), ('crooked.com', 'actblue.com')]\n"
     ]
    }
   ],
   "source": [
    "audience_overlap_sites = load_level_data(os.path.join(_ALEXA_DATA_PATH, 'corpus_2020_audience_overlap_sites_scrapping_result.json'), level=1)\n",
    "audience_overlap_sites_NODES = create_audience_overlap_nodes(audience_overlap_sites)\n",
    "\n",
    "print(audience_overlap_sites_NODES[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>votesaveamerica.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>art19.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>promocodeportal.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>mediamatters.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>actblue.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source               target\n",
       "0  crooked.com  votesaveamerica.com\n",
       "1  crooked.com            art19.com\n",
       "2  crooked.com  promocodeportal.com\n",
       "3  crooked.com     mediamatters.org\n",
       "4  crooked.com          actblue.com"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df = pd.DataFrame(audience_overlap_sites_NODES, columns=['source', 'target'])\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28779, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df2 = pd.DataFrame()\n",
    "edge_df2['source'] = edge_df['target']\n",
    "edge_df2['target'] = edge_df['source']\n",
    "\n",
    "edge_df = pd.concat([edge_df, edge_df2]).drop_duplicates(keep = \"first\").reset_index()\n",
    "edge_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique nodes in edges: 10161 Sample: ['enabbaladi.net', 'peoplesplace.com.hk', 'globaltimes.cn', 'tyt.com', 'corporate-office-headquarters.com']\n"
     ]
    }
   ],
   "source": [
    "nodes_in_edges = list(set(edge_df.source.unique().tolist() + edge_df.target.unique().tolist()))\n",
    "print('Number of unique nodes in edges:', len(nodes_in_edges), 'Sample:', nodes_in_edges[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alexa_rank</th>\n",
       "      <th>daily_pageviews_per_visitor</th>\n",
       "      <th>daily_time_on_site</th>\n",
       "      <th>total_sites_linking_in</th>\n",
       "      <th>bounce_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whistleblowersandrelators.com</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geokov.com</th>\n",
       "      <td>2238341.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trainingandfacilitation.ca</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plumsolutions.com.au</th>\n",
       "      <td>1023533.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbdailyupdate.com</th>\n",
       "      <td>145283.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>179.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               alexa_rank  daily_pageviews_per_visitor  \\\n",
       "site                                                                     \n",
       "whistleblowersandrelators.com         NaN                          NaN   \n",
       "geokov.com                      2238341.0                          1.0   \n",
       "trainingandfacilitation.ca            NaN                          NaN   \n",
       "plumsolutions.com.au            1023533.0                          1.0   \n",
       "dbdailyupdate.com                145283.0                          1.7   \n",
       "\n",
       "                               daily_time_on_site  total_sites_linking_in  \\\n",
       "site                                                                        \n",
       "whistleblowersandrelators.com                 NaN                     NaN   \n",
       "geokov.com                                    NaN                    60.0   \n",
       "trainingandfacilitation.ca                    NaN                     NaN   \n",
       "plumsolutions.com.au                        138.0                    60.0   \n",
       "dbdailyupdate.com                           179.0                    64.0   \n",
       "\n",
       "                               bounce_rate  \n",
       "site                                        \n",
       "whistleblowersandrelators.com          NaN  \n",
       "geokov.com                           0.900  \n",
       "trainingandfacilitation.ca             NaN  \n",
       "plumsolutions.com.au                 0.813  \n",
       "dbdailyupdate.com                    0.756  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_df = load_node_features()\n",
    "node_features_df = node_features_df.set_index('site')\n",
    "node_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10161 entries, enabbaladi.net to ptinews.com\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   alexa_rank                   7465 non-null   float64\n",
      " 1   daily_pageviews_per_visitor  7466 non-null   float64\n",
      " 2   daily_time_on_site           5566 non-null   float64\n",
      " 3   total_sites_linking_in       9861 non-null   float64\n",
      " 4   bounce_rate                  5179 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 476.3+ KB\n"
     ]
    }
   ],
   "source": [
    "node_features_df = node_features_df.loc[nodes_in_edges]\n",
    "node_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10161 entries, enabbaladi.net to ptinews.com\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   alexa_rank                   10161 non-null  float64\n",
      " 1   daily_pageviews_per_visitor  10161 non-null  float64\n",
      " 2   daily_time_on_site           10161 non-null  float64\n",
      " 3   total_sites_linking_in       10161 non-null  float64\n",
      " 4   bounce_rate                  10161 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 476.3+ KB\n"
     ]
    }
   ],
   "source": [
    "node_features_df.alexa_rank = node_features_df.alexa_rank.fillna(1000000)\n",
    "node_features_df.total_sites_linking_in = node_features_df.total_sites_linking_in.fillna(0)\n",
    "node_features_df.daily_pageviews_per_visitor  = node_features_df.daily_pageviews_per_visitor.fillna(0)\n",
    "node_features_df.daily_time_on_site = node_features_df.daily_time_on_site.fillna(0)\n",
    "node_features_df.bounce_rate = node_features_df.bounce_rate.fillna(0)\n",
    "node_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "node_features_df['normalized_alexa_rank'] = node_features_df['alexa_rank'].apply(lambda x: 1/x if x else 0)\n",
    "node_features_df['normalized_total_sites_linked_in'] = node_features_df['total_sites_linking_in'].apply(lambda x: math.log2(x) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alexa_rank</th>\n",
       "      <th>daily_pageviews_per_visitor</th>\n",
       "      <th>daily_time_on_site</th>\n",
       "      <th>total_sites_linking_in</th>\n",
       "      <th>bounce_rate</th>\n",
       "      <th>normalized_alexa_rank</th>\n",
       "      <th>normalized_total_sites_linked_in</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enabbaladi.net</th>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>3.062508e-04</td>\n",
       "      <td>0.524</td>\n",
       "      <td>4.916382e-05</td>\n",
       "      <td>0.460731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peoplesplace.com.hk</th>\n",
       "      <td>0.381432</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.094543e-07</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.498659e-07</td>\n",
       "      <td>0.046198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>globaltimes.cn</th>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.051211</td>\n",
       "      <td>1.556546e-03</td>\n",
       "      <td>0.586</td>\n",
       "      <td>4.377879e-05</td>\n",
       "      <td>0.569092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tyt.com</th>\n",
       "      <td>0.013515</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.037370</td>\n",
       "      <td>2.102617e-05</td>\n",
       "      <td>0.509</td>\n",
       "      <td>6.745475e-06</td>\n",
       "      <td>0.282201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corporate-office-headquarters.com</th>\n",
       "      <td>0.021136</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>2.681599e-05</td>\n",
       "      <td>0.929</td>\n",
       "      <td>4.279860e-06</td>\n",
       "      <td>0.298413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   alexa_rank  daily_pageviews_per_visitor  \\\n",
       "site                                                                         \n",
       "enabbaladi.net                       0.001876                     0.083333   \n",
       "peoplesplace.com.hk                  0.381432                     0.055556   \n",
       "globaltimes.cn                       0.002106                     0.058333   \n",
       "tyt.com                              0.013515                     0.066667   \n",
       "corporate-office-headquarters.com    0.021136                     0.027778   \n",
       "\n",
       "                                   daily_time_on_site  total_sites_linking_in  \\\n",
       "site                                                                            \n",
       "enabbaladi.net                               0.113725            3.062508e-04   \n",
       "peoplesplace.com.hk                          0.000000            6.094543e-07   \n",
       "globaltimes.cn                               0.051211            1.556546e-03   \n",
       "tyt.com                                      0.037370            2.102617e-05   \n",
       "corporate-office-headquarters.com            0.013610            2.681599e-05   \n",
       "\n",
       "                                   bounce_rate  normalized_alexa_rank  \\\n",
       "site                                                                    \n",
       "enabbaladi.net                           0.524           4.916382e-05   \n",
       "peoplesplace.com.hk                      0.000           1.498659e-07   \n",
       "globaltimes.cn                           0.586           4.377879e-05   \n",
       "tyt.com                                  0.509           6.745475e-06   \n",
       "corporate-office-headquarters.com        0.929           4.279860e-06   \n",
       "\n",
       "                                   normalized_total_sites_linked_in  \n",
       "site                                                                 \n",
       "enabbaladi.net                                             0.460731  \n",
       "peoplesplace.com.hk                                        0.046198  \n",
       "globaltimes.cn                                             0.569092  \n",
       "tyt.com                                                    0.282201  \n",
       "corporate-office-headquarters.com                          0.298413  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "node_features_df[['alexa_rank', 'daily_pageviews_per_visitor', 'daily_time_on_site',\n",
    "       'total_sites_linking_in', 'bounce_rate', 'normalized_alexa_rank',\n",
    "       'normalized_total_sites_linked_in']] = scaler.fit_transform(node_features_df[['alexa_rank', 'daily_pageviews_per_visitor', 'daily_time_on_site',\n",
    "       'total_sites_linking_in', 'bounce_rate', 'normalized_alexa_rank',\n",
    "       'normalized_total_sites_linked_in']])\n",
    "node_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_map = {dom:i for i, dom in enumerate(node_features_df.index)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9458</td>\n",
       "      <td>3172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9458</td>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9458</td>\n",
       "      <td>4367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9458</td>\n",
       "      <td>8875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9458</td>\n",
       "      <td>6691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target\n",
       "0    9458    3172\n",
       "1    9458    4857\n",
       "2    9458    4367\n",
       "3    9458    8875\n",
       "4    9458    6691"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df3 = pd.DataFrame()\n",
    "edge_df3['source'] = edge_df['source'].map(node_map)    \n",
    "edge_df3['target'] = edge_df['target'].map(node_map)\n",
    "edge_df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anything\n"
     ]
    }
   ],
   "source": [
    "print(\"anything\")\n",
    "breakpoint()\n",
    "data = create_dataset(list(zip(edge_df3['source'], edge_df3['target'])),\n",
    "                     list(zip(node_features_df['alexa_rank'], \n",
    "                              node_features_df['daily_pageviews_per_visitor'], \n",
    "                              node_features_df['daily_time_on_site'],\n",
    "                              node_features_df['total_sites_linking_in'], \n",
    "                              node_features_df['bounce_rate'], \n",
    "                              node_features_df['normalized_alexa_rank'],\n",
    "                              node_features_df['normalized_total_sites_linked_in'])),\n",
    "                     [1] * node_features_df.shape[0], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[10161, 7], edge_index=[2, 28779], y=[10161])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b79b6eaa13146153e76cad7b08d51586ae62e74b2c446d36f46103eaed4be7a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
