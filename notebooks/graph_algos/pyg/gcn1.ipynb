{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.nn import GNNExplainer\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborSampler #as RawNeighborSampler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch_cluster import random_walk\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def create_dataset(edges, features, labels, train_mask, test_mask):\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "    x = torch.tensor(features, dtype = torch.float)\n",
    "    y = torch.tensor(labels, dtype = torch.long)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index.t().contiguous(), y=y)\n",
    "    \n",
    "    #supervised setting\n",
    "    if train_mask != None:\n",
    "        data.train_mask = torch.tensor(train_mask, dtype = torch.bool)\n",
    "        if test_mask == None:\n",
    "            data.test_mask = ~data.train_mask\n",
    "        \n",
    "    #semi-supervised setting\n",
    "    if test_mask != None:\n",
    "        data.test_mask = torch.tensor(test_mask, dtype = torch.bool)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborLoaderX(NeighborLoader):\n",
    "    def sample(self, batch):\n",
    "        batch = torch.tensor(batch)\n",
    "        row, col, _ = self.adj_t.coo()\n",
    "\n",
    "        # For each node in `batch`, we sample a direct neighbor (as positive\n",
    "        # example) and a random node (as negative example):\n",
    "        pos_batch = random_walk(row, col, batch, walk_length=1,\n",
    "                                coalesced=False)[:, 1]\n",
    "\n",
    "        neg_batch = torch.randint(0, self.adj_t.size(1), (batch.numel(), ),\n",
    "                                  dtype=torch.long)\n",
    "\n",
    "        batch = torch.cat([batch, pos_batch, neg_batch], dim=0)\n",
    "        batch1 = super(NeighborLoaderX, self).sample(batch)\n",
    "        return batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels,\n",
    "                 hidden_channels,\n",
    "                 #out_dim,\n",
    "                 num_layers):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else hidden_channels\n",
    "            self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        # # post-message-passing\n",
    "        # self.post_mp = nn.Sequential(\n",
    "        #     nn.Linear(hidden_channels, hidden_channels), nn.Dropout(0.25), \n",
    "        #     nn.Linear(hidden_channels, out_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        #x = self.post_mp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(data, hidden_channels = 128, num_layers = 3, batch_size = 256):\n",
    "    print(\"Entered prepare()\")\n",
    "    train_mask = torch.ones(10161, dtype=torch.bool)\n",
    "    train_loader = NeighborLoaderX(data, input_nodes=train_mask, num_neighbors=[10]*2,\n",
    "                            shuffle=True,  batch_size = 256)\n",
    "    print(\"train_loader= {}\".format(train_loader))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"#features = {}\".format(data.num_node_features))\n",
    "    #print(\"Num layers \", num_layers)\n",
    "    model = GCN(data.num_node_features, hidden_channels=hidden_channels, num_layers=num_layers)\n",
    "    #model = GCN(data.num_node_features,64, 64)\n",
    "    #model = Encoder(data.num_node_features, 64)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    x, edge_index = data.x.to(device), data.edge_index.to(device)\n",
    "    return model, optimizer, x, edge_index, train_loader, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, device):\n",
    "    print(\"Entered train()\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x.to(device), batch.edge_index.to(device))\n",
    "        out, pos_out, neg_out = out.split(out.size(0) // 3, dim=0)\n",
    "        pos_loss = F.logsigmoid((out * pos_out).sum(-1)).mean()\n",
    "        neg_loss = F.logsigmoid(-(out * neg_out).sum(-1)).mean()\n",
    "        loss = -pos_loss - neg_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * out.size(0)\n",
    "        total_loss += float(loss)\n",
    "\n",
    "\n",
    "    return total_loss / data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(data, nepochs):\n",
    "    print(\"Entered train_all()\")\n",
    "    model, optimizer, x, edge_index, train_loader, device = prepare(data)\n",
    "    print(model)\n",
    "\n",
    "    for epoch in range(1, nepochs+1):\n",
    "        loss = train(model, optimizer, train_loader, device)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    return model, x, edge_index\n",
    "\n",
    "\n",
    "def predict_all(model, x, edge_index):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        #out = model.full_forward(x, edge_index).cpu()\n",
    "        out = model(x, edge_index).cpu()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, x, edge_index = train_all(data, 1)\n",
    "### This code is giving error \"too many values to unpack\" at line \"out, pos_out, neg_out = out.split(out.size(0) // 3, dim=0)\" because it was accepting exactly 3* batchsize as was Neigbour sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "2023-02-22 17:54:22.321332: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 17:54:22.328966: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "from notebooks.utils import _ALEXA_DATA_PATH, load_node_features, load_level_data, create_audience_overlap_nodes, export_model_as_feature\n",
    "from train import run_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-22 17:54:23 notebooks.utils INFO     Loaded 3489 nodes with records level <= 1 and child size:16981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('crooked.com', 'votesaveamerica.com'), ('crooked.com', 'art19.com'), ('crooked.com', 'promocodeportal.com'), ('crooked.com', 'mediamatters.org'), ('crooked.com', 'actblue.com')]\n"
     ]
    }
   ],
   "source": [
    "audience_overlap_sites = load_level_data(os.path.join(_ALEXA_DATA_PATH, 'corpus_2020_audience_overlap_sites_scrapping_result.json'), level=1)\n",
    "audience_overlap_sites_NODES = create_audience_overlap_nodes(audience_overlap_sites)\n",
    "\n",
    "print(audience_overlap_sites_NODES[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>votesaveamerica.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>art19.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>promocodeportal.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>mediamatters.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>actblue.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source               target\n",
       "0  crooked.com  votesaveamerica.com\n",
       "1  crooked.com            art19.com\n",
       "2  crooked.com  promocodeportal.com\n",
       "3  crooked.com     mediamatters.org\n",
       "4  crooked.com          actblue.com"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df = pd.DataFrame(audience_overlap_sites_NODES, columns=['source', 'target'])\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28779, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df2 = pd.DataFrame()\n",
    "edge_df2['source'] = edge_df['target']\n",
    "edge_df2['target'] = edge_df['source']\n",
    "\n",
    "edge_df = pd.concat([edge_df, edge_df2]).drop_duplicates(keep = \"first\").reset_index()\n",
    "edge_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique nodes in edges: 10161 Sample: ['leftvoice.org', 'windquest.com', 'iowahouserepublicans.com', 'uni-muenchen.de', 'everydayinbox.com']\n"
     ]
    }
   ],
   "source": [
    "nodes_in_edges = list(set(edge_df.source.unique().tolist() + edge_df.target.unique().tolist()))\n",
    "print('Number of unique nodes in edges:', len(nodes_in_edges), 'Sample:', nodes_in_edges[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alexa_rank</th>\n",
       "      <th>daily_pageviews_per_visitor</th>\n",
       "      <th>daily_time_on_site</th>\n",
       "      <th>total_sites_linking_in</th>\n",
       "      <th>bounce_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whistleblowersandrelators.com</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geokov.com</th>\n",
       "      <td>2238341.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trainingandfacilitation.ca</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plumsolutions.com.au</th>\n",
       "      <td>1023533.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbdailyupdate.com</th>\n",
       "      <td>145283.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>179.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               alexa_rank  daily_pageviews_per_visitor  \\\n",
       "site                                                                     \n",
       "whistleblowersandrelators.com         NaN                          NaN   \n",
       "geokov.com                      2238341.0                          1.0   \n",
       "trainingandfacilitation.ca            NaN                          NaN   \n",
       "plumsolutions.com.au            1023533.0                          1.0   \n",
       "dbdailyupdate.com                145283.0                          1.7   \n",
       "\n",
       "                               daily_time_on_site  total_sites_linking_in  \\\n",
       "site                                                                        \n",
       "whistleblowersandrelators.com                 NaN                     NaN   \n",
       "geokov.com                                    NaN                    60.0   \n",
       "trainingandfacilitation.ca                    NaN                     NaN   \n",
       "plumsolutions.com.au                        138.0                    60.0   \n",
       "dbdailyupdate.com                           179.0                    64.0   \n",
       "\n",
       "                               bounce_rate  \n",
       "site                                        \n",
       "whistleblowersandrelators.com          NaN  \n",
       "geokov.com                           0.900  \n",
       "trainingandfacilitation.ca             NaN  \n",
       "plumsolutions.com.au                 0.813  \n",
       "dbdailyupdate.com                    0.756  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_df = load_node_features()\n",
    "node_features_df = node_features_df.set_index('site')\n",
    "node_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10161 entries, leftvoice.org to sfhoardingcleanup.com\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   alexa_rank                   7465 non-null   float64\n",
      " 1   daily_pageviews_per_visitor  7466 non-null   float64\n",
      " 2   daily_time_on_site           5566 non-null   float64\n",
      " 3   total_sites_linking_in       9861 non-null   float64\n",
      " 4   bounce_rate                  5179 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 476.3+ KB\n"
     ]
    }
   ],
   "source": [
    "node_features_df = node_features_df.loc[nodes_in_edges]\n",
    "node_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10161 entries, leftvoice.org to sfhoardingcleanup.com\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   alexa_rank                   10161 non-null  float64\n",
      " 1   daily_pageviews_per_visitor  10161 non-null  float64\n",
      " 2   daily_time_on_site           10161 non-null  float64\n",
      " 3   total_sites_linking_in       10161 non-null  float64\n",
      " 4   bounce_rate                  10161 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 476.3+ KB\n"
     ]
    }
   ],
   "source": [
    "node_features_df.alexa_rank = node_features_df.alexa_rank.fillna(1000000)\n",
    "node_features_df.total_sites_linking_in = node_features_df.total_sites_linking_in.fillna(0)\n",
    "node_features_df.daily_pageviews_per_visitor  = node_features_df.daily_pageviews_per_visitor.fillna(0)\n",
    "node_features_df.daily_time_on_site = node_features_df.daily_time_on_site.fillna(0)\n",
    "node_features_df.bounce_rate = node_features_df.bounce_rate.fillna(0)\n",
    "node_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "node_features_df['normalized_alexa_rank'] = node_features_df['alexa_rank'].apply(lambda x: 1/x if x else 0)\n",
    "node_features_df['normalized_total_sites_linked_in'] = node_features_df['total_sites_linking_in'].apply(lambda x: math.log2(x) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alexa_rank</th>\n",
       "      <th>daily_pageviews_per_visitor</th>\n",
       "      <th>daily_time_on_site</th>\n",
       "      <th>total_sites_linking_in</th>\n",
       "      <th>bounce_rate</th>\n",
       "      <th>normalized_alexa_rank</th>\n",
       "      <th>normalized_total_sites_linked_in</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leftvoice.org</th>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.030219</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.819</td>\n",
       "      <td>7.501467e-06</td>\n",
       "      <td>0.365282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windquest.com</th>\n",
       "      <td>0.092413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.075871e-07</td>\n",
       "      <td>0.238840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iowahouserepublicans.com</th>\n",
       "      <td>0.092413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.075871e-07</td>\n",
       "      <td>0.312062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni-muenchen.de</th>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.616</td>\n",
       "      <td>1.029154e-04</td>\n",
       "      <td>0.594138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everydayinbox.com</th>\n",
       "      <td>0.092413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.075871e-07</td>\n",
       "      <td>0.159819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          alexa_rank  daily_pageviews_per_visitor  \\\n",
       "site                                                                \n",
       "leftvoice.org               0.012169                     0.041667   \n",
       "windquest.com               0.092413                     0.000000   \n",
       "iowahouserepublicans.com    0.092413                     0.000000   \n",
       "uni-muenchen.de             0.000897                     0.072222   \n",
       "everydayinbox.com           0.092413                     0.000000   \n",
       "\n",
       "                          daily_time_on_site  total_sites_linking_in  \\\n",
       "site                                                                   \n",
       "leftvoice.org                       0.030219                0.000073   \n",
       "windquest.com                       0.000000                0.000011   \n",
       "iowahouserepublicans.com            0.000000                0.000033   \n",
       "uni-muenchen.de                     0.034602                0.002267   \n",
       "everydayinbox.com                   0.000000                0.000003   \n",
       "\n",
       "                          bounce_rate  normalized_alexa_rank  \\\n",
       "site                                                           \n",
       "leftvoice.org                   0.819           7.501467e-06   \n",
       "windquest.com                   0.000           9.075871e-07   \n",
       "iowahouserepublicans.com        0.000           9.075871e-07   \n",
       "uni-muenchen.de                 0.616           1.029154e-04   \n",
       "everydayinbox.com               0.000           9.075871e-07   \n",
       "\n",
       "                          normalized_total_sites_linked_in  \n",
       "site                                                        \n",
       "leftvoice.org                                     0.365282  \n",
       "windquest.com                                     0.238840  \n",
       "iowahouserepublicans.com                          0.312062  \n",
       "uni-muenchen.de                                   0.594138  \n",
       "everydayinbox.com                                 0.159819  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "node_features_df[['alexa_rank', 'daily_pageviews_per_visitor', 'daily_time_on_site',\n",
    "       'total_sites_linking_in', 'bounce_rate', 'normalized_alexa_rank',\n",
    "       'normalized_total_sites_linked_in']] = scaler.fit_transform(node_features_df[['alexa_rank', 'daily_pageviews_per_visitor', 'daily_time_on_site',\n",
    "       'total_sites_linking_in', 'bounce_rate', 'normalized_alexa_rank',\n",
    "       'normalized_total_sites_linked_in']])\n",
    "node_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_map = {dom:i for i, dom in enumerate(node_features_df.index)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4187</td>\n",
       "      <td>9957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4187</td>\n",
       "      <td>9775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4187</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4187</td>\n",
       "      <td>6849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4187</td>\n",
       "      <td>3867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target\n",
       "0    4187    9957\n",
       "1    4187    9775\n",
       "2    4187    2812\n",
       "3    4187    6849\n",
       "4    4187    3867"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df3 = pd.DataFrame()\n",
    "edge_df3['source'] = edge_df['source'].map(node_map)    \n",
    "edge_df3['target'] = edge_df['target'].map(node_map)\n",
    "edge_df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_dataset(list(zip(edge_df3['source'], edge_df3['target'])),\n",
    "                     list(zip(node_features_df['alexa_rank'], \n",
    "                              node_features_df['daily_pageviews_per_visitor'], \n",
    "                              node_features_df['daily_time_on_site'],\n",
    "                              node_features_df['total_sites_linking_in'], \n",
    "                              node_features_df['bounce_rate'], \n",
    "                              node_features_df['normalized_alexa_rank'],\n",
    "                              node_features_df['normalized_total_sites_linked_in'])),\n",
    "                     [1] * node_features_df.shape[0], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[10161, 7], edge_index=[2, 28779], y=[10161])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b79b6eaa13146153e76cad7b08d51586ae62e74b2c446d36f46103eaed4be7a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
