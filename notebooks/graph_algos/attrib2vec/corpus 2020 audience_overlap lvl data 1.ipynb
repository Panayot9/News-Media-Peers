{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-26 10:11:45.745994: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from utils import _ALEXA_DATA_PATH, ModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_file = os.path.join(_ALEXA_DATA_PATH, \"corpus_2020_audience_overlap_level_0_and_1_node_features.csv\")\n",
    "edge_file = os.path.join(_ALEXA_DATA_PATH, \"combined_data_corpus_2020_level_0_1_df_edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/panayot/Documents/News-Media-Peers/alexa_data/corpus_2020_audience_overlap_level_0_and_1_node_features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2j/1pr09r3d6sdb3zmyqck2fxm80000gn/T/ipykernel_69888/830867289.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnode_features_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_features_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnode_features_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/panayot/Documents/News-Media-Peers/alexa_data/corpus_2020_audience_overlap_level_0_and_1_node_features.csv'"
     ]
    }
   ],
   "source": [
    "node_features_df = pd.read_csv(node_features_file, index_col=0)\n",
    "node_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12303 entries, gradescope.com to growveg.com\n",
      "Data columns (total 5 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alexa_ranks                   9128 non-null   float64\n",
      " 1   daily_pageviews_per_visitors  9129 non-null   float64\n",
      " 2   daily_time_on_sites           6780 non-null   float64\n",
      " 3   total_sites_linking_ins       11966 non-null  float64\n",
      " 4   bounce_rate                   6300 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 576.7+ KB\n"
     ]
    }
   ],
   "source": [
    "node_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_df.alexa_ranks = node_features_df.alexa_ranks.fillna(0)\n",
    "node_features_df.total_sites_linking_ins = node_features_df.total_sites_linking_ins.fillna(0)\n",
    "node_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_df['normalized_alexa_rank'] = node_features_df['alexa_ranks'].apply(lambda x: 1/x if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "node_features_df['normalized_total_sites_linked_in'] = node_features_df['total_sites_linking_ins'].apply(lambda x: math.log2(x) if x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load edges\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>votesaveamerica.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>art19.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>promocodeportal.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>mediamatters.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crooked.com</td>\n",
       "      <td>actblue.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source               target\n",
       "0  crooked.com  votesaveamerica.com\n",
       "1  crooked.com            art19.com\n",
       "2  crooked.com  promocodeportal.com\n",
       "3  crooked.com     mediamatters.org\n",
       "4  crooked.com          actblue.com"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df = pd.read_csv(edge_file)\n",
    "\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28381 entries, 0 to 28380\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   source  28381 non-null  object\n",
      " 1   target  28381 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 443.6+ KB\n"
     ]
    }
   ],
   "source": [
    "edge_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stellargraph as sg\n",
    "\n",
    "G = sg.StellarGraph(node_features_df[['normalized_alexa_rank', 'normalized_total_sites_linked_in']], edge_df)\n",
    "print(G.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Attrib2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import Attri2VecLinkGenerator, Attri2VecNodeGenerator\n",
    "from stellargraph.layer import Attri2Vec, link_classification\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Specify the other optional parameter values: root nodes, the number of walks to take per node, the length of each walk, and random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(G.nodes())\n",
    "number_of_walks = 1\n",
    "length = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the UnsupervisedSampler instance with the relevant parameters passed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_samples = UnsupervisedSampler(G, nodes=nodes, length=length, number_of_walks=number_of_walks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a node pair generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 4\n",
    "num_samples = [10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Attri2VecLinkGenerator(G, batch_size)\n",
    "train_gen = generator.flow(unsupervised_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [128]\n",
    "attri2vec = Attri2Vec(layer_sizes=layer_sizes, generator=generator, bias=False, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and expose input and output sockets of attri2vec, for node pair inputs:\n",
    "x_inp, x_out = attri2vec.in_out_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'ip' method to combine node embeddings into edge embeddings\n"
     ]
    }
   ],
   "source": [
    "prediction = link_classification(output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\")(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=[keras.metrics.binary_accuracy],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1969/1969 - 27s - loss: 0.6562 - binary_accuracy: 0.5589\n",
      "Epoch 2/32\n",
      "1969/1969 - 26s - loss: 0.6530 - binary_accuracy: 0.5655\n",
      "Epoch 3/32\n",
      "1969/1969 - 27s - loss: 0.6534 - binary_accuracy: 0.5657\n",
      "Epoch 4/32\n",
      "1969/1969 - 22s - loss: 0.6538 - binary_accuracy: 0.5700\n",
      "Epoch 5/32\n",
      "1969/1969 - 22s - loss: 0.6526 - binary_accuracy: 0.5698\n",
      "Epoch 6/32\n",
      "1969/1969 - 23s - loss: 0.6549 - binary_accuracy: 0.5746\n",
      "Epoch 7/32\n",
      "1969/1969 - 22s - loss: 0.6529 - binary_accuracy: 0.5786\n",
      "Epoch 8/32\n",
      "1969/1969 - 25s - loss: 0.6512 - binary_accuracy: 0.5834\n",
      "Epoch 9/32\n",
      "1969/1969 - 22s - loss: 0.6514 - binary_accuracy: 0.5840\n",
      "Epoch 10/32\n",
      "1969/1969 - 23s - loss: 0.6523 - binary_accuracy: 0.5898\n",
      "Epoch 11/32\n",
      "1969/1969 - 22s - loss: 0.6547 - binary_accuracy: 0.5903\n",
      "Epoch 12/32\n",
      "1969/1969 - 23s - loss: 0.6520 - binary_accuracy: 0.5958\n",
      "Epoch 13/32\n",
      "1969/1969 - 24s - loss: 0.6538 - binary_accuracy: 0.5966\n",
      "Epoch 14/32\n",
      "1969/1969 - 27s - loss: 0.6542 - binary_accuracy: 0.6030\n",
      "Epoch 15/32\n",
      "1969/1969 - 22s - loss: 0.6493 - binary_accuracy: 0.6081\n",
      "Epoch 16/32\n",
      "1969/1969 - 23s - loss: 0.6482 - binary_accuracy: 0.6130\n",
      "Epoch 17/32\n",
      "1969/1969 - 23s - loss: 0.6527 - binary_accuracy: 0.6182\n",
      "Epoch 18/32\n",
      "1969/1969 - 24s - loss: 0.6481 - binary_accuracy: 0.6245\n",
      "Epoch 19/32\n",
      "1969/1969 - 24s - loss: 0.6476 - binary_accuracy: 0.6296\n",
      "Epoch 20/32\n",
      "1969/1969 - 23s - loss: 0.6455 - binary_accuracy: 0.6343\n",
      "Epoch 21/32\n",
      "1969/1969 - 24s - loss: 0.6390 - binary_accuracy: 0.6401\n",
      "Epoch 22/32\n",
      "1969/1969 - 21s - loss: 0.6441 - binary_accuracy: 0.6460\n",
      "Epoch 23/32\n",
      "1969/1969 - 22s - loss: 0.6462 - binary_accuracy: 0.6431\n",
      "Epoch 24/32\n",
      "1969/1969 - 22s - loss: 0.6417 - binary_accuracy: 0.6481\n",
      "Epoch 25/32\n",
      "1969/1969 - 21s - loss: 0.6422 - binary_accuracy: 0.6502\n",
      "Epoch 26/32\n",
      "1969/1969 - 20s - loss: 0.6364 - binary_accuracy: 0.6515\n",
      "Epoch 27/32\n",
      "1969/1969 - 22s - loss: 0.6399 - binary_accuracy: 0.6529\n",
      "Epoch 28/32\n",
      "1969/1969 - 19s - loss: 0.6352 - binary_accuracy: 0.6571\n",
      "Epoch 29/32\n",
      "1969/1969 - 20s - loss: 0.6391 - binary_accuracy: 0.6544\n",
      "Epoch 30/32\n",
      "1969/1969 - 21s - loss: 0.6341 - binary_accuracy: 0.6578\n",
      "Epoch 31/32\n",
      "1969/1969 - 21s - loss: 0.6314 - binary_accuracy: 0.6617\n",
      "Epoch 32/32\n",
      "1969/1969 - 21s - loss: 0.6337 - binary_accuracy: 0.6615\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=32\n",
    "    verbose=2,\n",
    "    use_multiprocessing=False,\n",
    "    workers=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# \"\"\"\n",
    "# previous before normalization\n",
    "\n",
    "# WARNING:tensorflow:sample_weight modes were coerced from\n",
    "#   ...\n",
    "#     to  \n",
    "#   ['...']\n",
    "# Train for 1899 steps\n",
    "# Epoch 1/8\n",
    "# 1899/1899 - 47s - loss: 0.7380 - binary_accuracy: 0.5427\n",
    "# Epoch 2/8\n",
    "# 1899/1899 - 46s - loss: 0.6368 - binary_accuracy: 0.6424\n",
    "# Epoch 3/8\n",
    "# 1899/1899 - 47s - loss: 0.5929 - binary_accuracy: 0.6680\n",
    "# Epoch 4/8\n",
    "# 1899/1899 - 48s - loss: 0.5694 - binary_accuracy: 0.6800\n",
    "# Epoch 5/8\n",
    "# 1899/1899 - 52s - loss: 0.5564 - binary_accuracy: 0.6865\n",
    "# Epoch 6/8\n",
    "# 1899/1899 - 47s - loss: 0.5442 - binary_accuracy: 0.6933\n",
    "# Epoch 7/8\n",
    "# 1899/1899 - 48s - loss: 0.5399 - binary_accuracy: 0.6941\n",
    "# Epoch 8/8\n",
    "# 1899/1899 - 47s - loss: 0.5272 - binary_accuracy: 0.7013\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp_src = x_inp[0]\n",
    "x_out_src = x_out[0]\n",
    "embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 0s 447us/step\n"
     ]
    }
   ],
   "source": [
    "node_gen = Attri2VecNodeGenerator(G, batch_size).flow(node_features_df.index)\n",
    "node_embeddings = embedding_model.predict(node_gen, workers=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_embeddings[213]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_wv = dict(zip(node_features_df.index.tolist(), node_embeddings.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0003732442855834961,\n",
       " 4.30028330811183e-06,\n",
       " 2.5482699129497632e-05,\n",
       " 3.3911762287175407e-10,\n",
       " 1.558484490635123e-23,\n",
       " 0.00019913911819458008,\n",
       " 0.00023236870765686035,\n",
       " 5.7033391342997675e-09,\n",
       " 0.05188429355621338,\n",
       " 0.029672235250473022,\n",
       " 5.8983729012140884e-09,\n",
       " 4.743696546682941e-10,\n",
       " 0.043988555669784546,\n",
       " 2.054232572845649e-05,\n",
       " 0.00021141767501831055,\n",
       " 0.04522329568862915,\n",
       " 0.00013944506645202637,\n",
       " 2.6334089852753095e-05,\n",
       " 1.3350941117096227e-05,\n",
       " 4.7838506489483734e-09,\n",
       " 1.7735639346039278e-10,\n",
       " 5.188054183712715e-22,\n",
       " 2.2235178601205473e-24,\n",
       " 8.901382386738987e-08,\n",
       " 1.5084044449280723e-23,\n",
       " 0.0004639625549316406,\n",
       " 3.986377123510465e-06,\n",
       " 9.197851914321486e-25,\n",
       " 0.03558462858200073,\n",
       " 2.815746938722441e-06,\n",
       " 0.042846739292144775,\n",
       " 0.031478822231292725,\n",
       " 0.0415743887424469,\n",
       " 0.052382439374923706,\n",
       " 0.000202864408493042,\n",
       " 2.745870875912741e-21,\n",
       " 2.3928846751286592e-11,\n",
       " 0.0001748204231262207,\n",
       " 2.2130896013550228e-06,\n",
       " 7.707193105943588e-08,\n",
       " 1.4789678125742662e-18,\n",
       " 0.0544050931930542,\n",
       " 2.747385874357633e-09,\n",
       " 0.032942503690719604,\n",
       " 9.75927672008936e-13,\n",
       " 0.03406238555908203,\n",
       " 1.3977422895550262e-05,\n",
       " 1.982829417102039e-05,\n",
       " 7.739945431239903e-05,\n",
       " 1.1811048139520608e-08,\n",
       " 0.03519684076309204,\n",
       " 0.04795581102371216,\n",
       " 4.106054257135838e-05,\n",
       " 9.849286860079665e-23,\n",
       " 5.806439773436978e-09,\n",
       " 5.561075340665411e-06,\n",
       " 7.873041613493115e-05,\n",
       " 1.8678463920371296e-23,\n",
       " 3.601044766734726e-21,\n",
       " 0.037512123584747314,\n",
       " 3.731506093515327e-20,\n",
       " 0.02952060103416443,\n",
       " 0.042511820793151855,\n",
       " 0.00012075986160198227,\n",
       " 6.318495726631568e-11,\n",
       " 3.6800745874643326e-05,\n",
       " 0.00017708539962768555,\n",
       " 0.034774959087371826,\n",
       " 7.421324443868116e-09,\n",
       " 0.00011078546958742663,\n",
       " 2.893804964348653e-23,\n",
       " 8.71035368277262e-08,\n",
       " 0.03661412000656128,\n",
       " 2.6953341148328036e-05,\n",
       " 4.3793796066893265e-05,\n",
       " 0.028940200805664062,\n",
       " 0.03295120596885681,\n",
       " 2.51317322508271e-09,\n",
       " 5.3101176789027704e-09,\n",
       " 1.6514163647673996e-10,\n",
       " 3.4524939279104505e-24,\n",
       " 6.075207693356788e-06,\n",
       " 1.4934785339581303e-22,\n",
       " 3.05365689828338e-24,\n",
       " 2.3883832023231802e-23,\n",
       " 1.1264677341957241e-12,\n",
       " 1.6222167687374167e-05,\n",
       " 4.887193990019489e-19,\n",
       " 8.998667766491053e-08,\n",
       " 0.0002186894416809082,\n",
       " 0.032734811305999756,\n",
       " 2.363795825743864e-09,\n",
       " 7.774100367896608e-07,\n",
       " 1.5582252672174945e-05,\n",
       " 0.00019156932830810547,\n",
       " 0.050298869609832764,\n",
       " 5.197501737536688e-15,\n",
       " 7.495681085617492e-17,\n",
       " 0.05078586935997009,\n",
       " 1.163055821962189e-05,\n",
       " 9.484983110041867e-08,\n",
       " 2.5422886018588997e-09,\n",
       " 0.03787916898727417,\n",
       " 0.035794198513031006,\n",
       " 0.03262472152709961,\n",
       " 6.172982125463022e-09,\n",
       " 4.1949721784871825e-24,\n",
       " 2.590992146738746e-24,\n",
       " 2.5868259854178177e-06,\n",
       " 0.034614890813827515,\n",
       " 1.985956714634085e-06,\n",
       " 1.6634831012662943e-10,\n",
       " 0.0002651214599609375,\n",
       " 9.368876817461569e-06,\n",
       " 0.9145092964172363,\n",
       " 1.661843816916679e-21,\n",
       " 6.989703628432586e-24,\n",
       " 1.1626949951718863e-17,\n",
       " 1.009188054013066e-05,\n",
       " 3.28553684258992e-10,\n",
       " 0.00013130903244018555,\n",
       " 3.343273533573665e-07,\n",
       " 0.03585505485534668,\n",
       " 3.074456981266849e-05,\n",
       " 7.050672474442744e-19,\n",
       " 0.026895344257354736,\n",
       " 1.5421584009800426e-07,\n",
       " 1.2148242108059913e-22]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_wv['crooked.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_year = '2020'\n",
    "node2vec_model = ModelWrapper('Unsupervised Attrib2Vec', embeddings_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Start training...\n",
      "Start training...\n",
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "result_report = []\n",
    "\n",
    "clf = LogisticRegressionCV(Cs=10, cv=5, scoring=\"accuracy\", multi_class=\"ovr\", max_iter=300, random_state=42)\n",
    "result_report.append([\n",
    "    str(model),\n",
    "    'LogisticRegression CV = 5',\n",
    "    *list(train_model(clf, node2vec_model=node2vec_model, data_year=data_year).values())\n",
    "]);\n",
    "\n",
    "clf2 = LogisticRegressionCV(Cs=10, cv=10, scoring=\"accuracy\", multi_class=\"ovr\", max_iter=300, random_state=42)\n",
    "result_report.append([\n",
    "    str(model),\n",
    "    'LogisticRegression CV = 10',\n",
    "    *list(train_model(clf2, node2vec_model=node2vec_model, data_year=data_year).values())\n",
    "]);\n",
    "\n",
    "tree_clf = GradientBoostingClassifier(random_state=42)\n",
    "result_report.append([\n",
    "    str(model),\n",
    "    'GradientBoostingClassifier',\n",
    "    *list(train_model(tree_clf, node2vec_model=node2vec_model, data_year=data_year).values())\n",
    "]);\n",
    "\n",
    "svm_clf = svm.SVC(decision_function_shape='ovo', probability=True, random_state=42)\n",
    "result_report.append([\n",
    "    str(model),\n",
    "    'SVC ovo',\n",
    "    *list(train_model(svm_clf, node2vec_model=node2vec_model, data_year=data_year).values())\n",
    "]);\n",
    "\n",
    "model_res = pd.DataFrame(result_report,\n",
    "                    columns=[\"Feature\", \"Classifier\", \"Accuracy\", \"Balanced Accuracy score\",\n",
    "                             \"F1 micro score\", \"F1 macro score\", \"F1 weighted score\", \"MAE\", \"Confusion matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy score</th>\n",
       "      <th>F1 micro score</th>\n",
       "      <th>F1 macro score</th>\n",
       "      <th>F1 weighted score</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Confusion matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;tensorflow.python.keras.engine.functional.Fun...</td>\n",
       "      <td>LogisticRegression CV = 5</td>\n",
       "      <td>0.544820</td>\n",
       "      <td>0.369032</td>\n",
       "      <td>0.544820</td>\n",
       "      <td>0.313669</td>\n",
       "      <td>0.437061</td>\n",
       "      <td>0.597206</td>\n",
       "      <td>[[3, 39, 120], [5, 32, 208], [2, 17, 433]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;tensorflow.python.keras.engine.functional.Fun...</td>\n",
       "      <td>LogisticRegression CV = 10</td>\n",
       "      <td>0.541327</td>\n",
       "      <td>0.364253</td>\n",
       "      <td>0.541327</td>\n",
       "      <td>0.305611</td>\n",
       "      <td>0.430852</td>\n",
       "      <td>0.601863</td>\n",
       "      <td>[[2, 39, 121], [5, 30, 210], [2, 17, 433]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;tensorflow.python.keras.engine.functional.Fun...</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.513388</td>\n",
       "      <td>0.392241</td>\n",
       "      <td>0.513388</td>\n",
       "      <td>0.380391</td>\n",
       "      <td>0.468926</td>\n",
       "      <td>0.636787</td>\n",
       "      <td>[[30, 38, 94], [42, 44, 159], [35, 50, 367]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;tensorflow.python.keras.engine.functional.Fun...</td>\n",
       "      <td>SVC ovo</td>\n",
       "      <td>0.543655</td>\n",
       "      <td>0.383852</td>\n",
       "      <td>0.543655</td>\n",
       "      <td>0.327749</td>\n",
       "      <td>0.429680</td>\n",
       "      <td>0.612340</td>\n",
       "      <td>[[28, 13, 121], [32, 4, 209], [13, 4, 435]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Feature  \\\n",
       "0  <tensorflow.python.keras.engine.functional.Fun...   \n",
       "1  <tensorflow.python.keras.engine.functional.Fun...   \n",
       "2  <tensorflow.python.keras.engine.functional.Fun...   \n",
       "3  <tensorflow.python.keras.engine.functional.Fun...   \n",
       "\n",
       "                   Classifier  Accuracy  Balanced Accuracy score  \\\n",
       "0   LogisticRegression CV = 5  0.544820                 0.369032   \n",
       "1  LogisticRegression CV = 10  0.541327                 0.364253   \n",
       "2  GradientBoostingClassifier  0.513388                 0.392241   \n",
       "3                     SVC ovo  0.543655                 0.383852   \n",
       "\n",
       "   F1 micro score  F1 macro score  F1 weighted score       MAE  \\\n",
       "0        0.544820        0.313669           0.437061  0.597206   \n",
       "1        0.541327        0.305611           0.430852  0.601863   \n",
       "2        0.513388        0.380391           0.468926  0.636787   \n",
       "3        0.543655        0.327749           0.429680  0.612340   \n",
       "\n",
       "                               Confusion matrix  \n",
       "0    [[3, 39, 120], [5, 32, 208], [2, 17, 433]]  \n",
       "1    [[2, 39, 121], [5, 30, 210], [2, 17, 433]]  \n",
       "2  [[30, 38, 94], [42, 44, 159], [35, 50, 367]]  \n",
       "3   [[28, 13, 121], [32, 4, 209], [13, 4, 435]]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('attrib2vec.json', 'w') as f:\n",
    "    json.dump(node2vec_model.wv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "940b4c110c3cebababd37dc6cec19477a44e469d32c41a0eaa8eeb689ff0386b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('site_similarity': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "72b3faef5542ae75c34eb0d3b11ce0fc432eb00b9ccfc309dfbebb58f482608a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
