{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (1.10.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (4.15.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: sacremoses in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from requests->transformers) (2.0.9)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/mediapeers/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.3)\n"
     ]
    }
   ],
   "source": [
    "# ! pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 09:21:09.418394: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../../../')\n",
    "from notebooks.utils import _ARTICLES_2020, load_json, export_model_as_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "TOKENIZER = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "MODEL = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# MODEL.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roberta_embeddings(text):\n",
    "    # Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "    # text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "    #     \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "    encoded_dict = TOKENIZER.encode(\n",
    "                        text,                       # article to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 510,           # Pad & truncate all articles.\n",
    "                        padding = True,\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    difference = 510 - encoded_dict.shape[1]\n",
    "    if difference:\n",
    "        encoded_dict = torch.cat(\n",
    "                (encoded_dict, torch.Tensor([[0] * difference])),\n",
    "                dim=-1\n",
    "        )\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = encoded_dict.to(device)\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    MODEL.eval()\n",
    "\n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all 12 layers.\n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = MODEL(tokens_tensor.long())\n",
    "\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "    # `hidden_states` has shape [1, 510, 768]\n",
    "\n",
    "    # `token_vecs` is a tensor with shape [510, 768]\n",
    "    token_vecs = hidden_states[0]\n",
    "\n",
    "    # Calculate the average of all 510 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "    return sentence_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04898376762866974,\n",
       " 0.08267765492200851,\n",
       " -0.008879145607352257,\n",
       " -0.11193916201591492,\n",
       " 0.07080987840890884,\n",
       " -0.06627613306045532,\n",
       " -0.050851985812187195,\n",
       " 0.0062030707485973835,\n",
       " 0.06748633831739426,\n",
       " -0.08248450607061386]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_roberta_embeddings('This is a stupid test.')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings for inthesetimes.com\n",
      "Generate embeddings for shareblue.com\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import json\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(_ARTICLES_2020, 'r') as zip_fd:\n",
    "    title_embeddings, body_embeddings = {}, {}\n",
    "    for site_file in [f for f in zip_fd.namelist() if f.endswith('.json')]:\n",
    "        site = os.path.basename(site_file).replace('.json', '')\n",
    "        print('Generate embeddings for', site)\n",
    "        with zip_fd.open(site_file) as site_fd:\n",
    "            articles_for_site = json.load(site_fd)\n",
    "            title_embed, body_embed  = [], []\n",
    "            for article in articles_for_site:\n",
    "                title_embed.append(get_roberta_embeddings(article['title']))\n",
    "                body_embed.append(get_roberta_embeddings(article['body']))\n",
    "\n",
    "        title_embeddings[site] = torch.Tensor(title_embed).mean(dim=0).tolist()\n",
    "        body_embeddings[site] = torch.Tensor(body_embed).mean(dim=0).tolist()\n",
    "\n",
    "    export_model_as_feature(title_embeddings, 'roberta_title_embeddings_768d.json')\n",
    "    export_model_as_feature(body_embeddings, 'roberta_body_embeddings_768d.json')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "940b4c110c3cebababd37dc6cec19477a44e469d32c41a0eaa8eeb689ff0386b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('mediapeers': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
